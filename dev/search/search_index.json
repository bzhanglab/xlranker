{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"XLRanker <p>XLRanker is a tool to rank and prioritize protein to protein cross linking data. The tool uses parsimonious selection as well as an XGBoost model to select the best protein pairs to represent ambiguous peptides.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install <code>xlranker</code> using pip:</p> <pre><code>pip install xlranker\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>Please view the usage documentation for detailed usage instructions and examples.</p>"},{"location":"#example-notebook","title":"Example Notebook","text":"<p>For a quick start, you can check out the example notebook in the <code>notebooks</code> directory or launch a google colab notebook to see how to use the package interactively.</p>"},{"location":"API/","title":"XLRanker API","text":"<p>If you are not using the XLRanker CLI, you can use the Python library. This may be useful if you are using a Jupyter Notebook, or you only intend to use portions of the pipeline. This page has documentation for the different classes and methods used by the library.</p>"},{"location":"API/cli/","title":"CLI","text":"<p>This module contains the command line interface for XLRanker.</p>"},{"location":"API/config/","title":"Config","text":""},{"location":"API/config/#xlranker.config.AdvancedConfig","title":"<code>AdvancedConfig</code>  <code>dataclass</code>","text":"<p>Advanced config options for XLRanker</p> <p>Attributes:</p> Name Type Description <code>intra_in_training</code> <code>bool</code> <p>Default to False. If True, intra pairs are included in the positive set for model training. # TODO: May remove this option in future versions</p> Source code in <code>src/xlranker/config.py</code> <pre><code>@dataclass\nclass AdvancedConfig:\n    \"\"\"Advanced config options for XLRanker\n\n    Attributes:\n        intra_in_training (bool): Default to False. If True, intra pairs are included in the positive set for model training. # TODO: May remove this option in future versions\n\n    \"\"\"\n\n    intra_in_training: bool = False  # allow intra in training data\n</code></pre>"},{"location":"API/config/#xlranker.config.Config","title":"<code>Config</code>  <code>dataclass</code>","text":"<p>Config for XLRanker</p> <p>Attributes:</p> Name Type Description <code>fragile</code> <code>bool</code> <p>Default to False. If True, throw error on any warning</p> <code>detailed</code> <code>bool</code> <p>Default to False. If True, perform more analysis about dataset</p> <code>reduce_fasta</code> <code>bool</code> <p>Default to True. If True, when a gene has multiple sequences, only accept longest sequence as the canonical sequence.</p> <code>intra_in_training</code> <code>bool</code> <p>Default to False. If True, intra pairs are included in the positive set for model training.</p> <code>output</code> <code>str</code> <p>Default to \"xlranker_output/\". Directory where output files are saved.</p> <code>additional_null_values</code> <code>list[str]</code> <p>Default to []. Additional null values to consider when reading data files.</p> Source code in <code>src/xlranker/config.py</code> <pre><code>@dataclass\nclass Config:\n    \"\"\"Config for XLRanker\n\n    Attributes:\n        fragile (bool): Default to False. If True, throw error on any warning\n        detailed (bool): Default to False. If True, perform more analysis about dataset\n        reduce_fasta (bool): Default to True. If True, when a gene has multiple sequences, only accept longest sequence as the canonical sequence.\n        intra_in_training (bool): Default to False. If True, intra pairs are included in the positive set for model training.\n        output (str): Default to \"xlranker_output/\". Directory where output files are saved.\n        additional_null_values (list[str]): Default to []. Additional null values to consider when reading data files.\n\n    \"\"\"\n\n    fragile: bool = False  # Break on any warning\n    detailed: bool = False  # Show more detailed information about dataset and analysis\n    reduce_fasta: bool = False  # Reduce FASTA file by only keeping the largest sequence\n    human_only: bool = True  # Is all data human only?\n    output: str = \"xlranker_output/\"  # output directory\n    additional_null_values: list[str] = field(\n        default_factory=list\n    )  # additional null values to consider when reading data files\n    advanced: AdvancedConfig = field(\n        default_factory=AdvancedConfig\n    )  # advanced config options\n</code></pre>"},{"location":"API/config/#xlranker.config.load_from_json","title":"<code>load_from_json(json_file)</code>","text":"<p>set config to settings in JSON file</p> <p>Parameters:</p> Name Type Description Default <code>json_file</code> <code>str</code> <p>path to JSON file</p> required Source code in <code>src/xlranker/config.py</code> <pre><code>def load_from_json(json_file: str) -&gt; None:\n    \"\"\"set config to settings in JSON file\n\n    Args:\n        json_file (str): path to JSON file\n\n    \"\"\"\n    with open(json_file) as r:\n        json_obj = json.load(r)\n    for key in json_obj:\n        setattr(config, key, json_obj[key])\n</code></pre>"},{"location":"API/config/#xlranker.config.set_config_from_dict","title":"<code>set_config_from_dict(config_dict)</code>","text":"<p>set config from a dict object</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>dict[str, Any]</code> <p>dictionary with config settings</p> required Source code in <code>src/xlranker/config.py</code> <pre><code>def set_config_from_dict(config_dict: dict[str, Any]) -&gt; None:\n    \"\"\"set config from a dict object\n\n    Args:\n        config_dict (dict[str, Any]): dictionary with config settings\n\n    \"\"\"\n\n    for key in config_dict:\n        setattr(config, key, config_dict[key])\n</code></pre>"},{"location":"API/lib/","title":"Lib","text":""},{"location":"API/lib/#xlranker.lib.XLDataSet","title":"<code>XLDataSet</code>","text":"<p>XLRanker cross-linking dataset object.</p> <p>Attributes:</p> Name Type Description <code>network</code> <code>dict[str, PeptidePair]</code> <p>Dictionary of peptide pairs, where the key is a unique identifier for the pair.</p> <code>omic_data</code> <code>dict[str, DataFrame]</code> <p>Dictionary of omic data, where the key is the file name and the value is a Polars DataFrame containing the data.</p> Source code in <code>src/xlranker/lib.py</code> <pre><code>class XLDataSet:\n    \"\"\"XLRanker cross-linking dataset object.\n\n    Attributes:\n        network (dict[str, PeptidePair]): Dictionary of peptide pairs, where the key is a unique identifier for the pair.\n        omic_data (dict[str, pl.DataFrame]): Dictionary of omic data, where the key is the file name and the value is a Polars DataFrame containing the data.\n    \"\"\"\n\n    peptide_pairs: dict[str, PeptidePair]\n    omic_data: dict[str, pl.DataFrame]\n    proteins: dict[str, Protein]\n    protein_pairs: dict[str, ProteinPair]\n\n    def __init__(\n        self, network: dict[str, PeptidePair], omic_data: dict[str, pl.DataFrame]\n    ):\n        self.peptide_pairs = network\n        self.omic_data = omic_data\n        self.protein_pairs = {}\n        self.proteins = {}\n\n    def build_proteins(self, remove_intra: bool = False) -&gt; None:\n        \"\"\"Build protein pairs of the XLDataSet network.\n\n        Args:\n            remove_intra (bool, optional): if true, only creates protein pairs between different proteins. Defaults to True.\n\n        \"\"\"\n        all_proteins: set[str] = set()\n        for p_peptide_pairs in self.peptide_pairs.values():\n            all_proteins = all_proteins.union(set(p_peptide_pairs.a.mapped_proteins))\n            all_proteins = all_proteins.union(set(p_peptide_pairs.b.mapped_proteins))\n        for protein in all_proteins:\n            abundances = {}\n            for omic_file in self.omic_data:\n                abundances[omic_file] = get_abundance(\n                    self.omic_data[omic_file], protein\n                )\n            self.proteins[protein] = Protein(protein, protein, abundances)\n        remove_pairs = []\n        for (\n            peptide_pair_key\n        ) in self.peptide_pairs.keys():  # TODO: Make this loop cleaner to read\n            peptide_pair = self.peptide_pairs[peptide_pair_key]\n            peptide_pair_id = get_pair_id(peptide_pair.a, peptide_pair.b)\n            had_intra = False\n            for protein_a_name in peptide_pair.a.mapped_proteins:\n                for protein_b_name in peptide_pair.b.mapped_proteins:\n                    if remove_intra and protein_a_name == protein_b_name:\n                        had_intra = True\n                        break\n            if had_intra:\n                remove_pairs.append(peptide_pair_key)\n            else:\n                for protein_a_name in peptide_pair.a.mapped_proteins:\n                    protein_a = self.proteins[protein_a_name]\n                    for protein_b_name in peptide_pair.b.mapped_proteins:\n                        protein_b = self.proteins[protein_b_name]\n                        protein_pair_id = get_pair_id(protein_a, protein_b)\n                        if protein_pair_id not in self.protein_pairs:\n                            new_pair = ProteinPair(protein_a, protein_b)\n                            self.protein_pairs[protein_pair_id] = new_pair\n                            peptide_pair.add_connection(protein_pair_id)\n                            new_pair.add_connection(peptide_pair_id)\n                        else:\n                            self.protein_pairs[protein_pair_id].add_connection(\n                                peptide_pair_id\n                            )\n                            peptide_pair.add_connection(protein_pair_id)\n        for key in remove_pairs:\n            self.peptide_pairs.pop(key)\n\n    @classmethod\n    def load_from_network(\n        cls,\n        network_path: str,\n        omics_data_folder: str,\n        custom_mapper: PeptideMapper | None = None,\n        custom_mapping_path: str | None = None,\n        is_fasta: bool = True,\n        split_by: str | None = \"|\",\n        split_index: int | None = 3,\n        fasta_type: str | FastaType = \"UNIPROT\",\n    ) -&gt; \"XLDataSet\":\n        \"\"\"Create a XLDataSet object from a network file.\n\n        Args:\n            network_path (str): path to the peptide pairs\n            omics_data_folder (str): folder containing the omic data\n            custom_mapper (PeptideMapper | None, optional): PeptideMapper object that should be used for mapping. If None, create peptide mapper using other parameters. Defaults to None.\n            custom_mapping_path (str | None, optional): _description_. Defaults to None.\n            is_fasta (bool, optional): _description_. Defaults to True.\n            split_by (str | None, optional): _description_. Defaults to \"|\".\n            split_index (int | None, optional): _description_. Defaults to 3.\n\n        Returns:\n            XLDataSet: XLDataSet with peptide pairs and omics data loaded\n\n        \"\"\"\n        split_by = \"|\" if split_by is None else split_by\n        split_index = 6 if split_index is None else split_index\n        network = read_network_file(network_path)\n        omic_data: dict[str, pl.DataFrame] = read_data_folder(omics_data_folder)\n        peptide_sequences = set()\n        for group in network.values():\n            peptide_sequences.add(group.a.sequence)\n            peptide_sequences.add(group.b.sequence)\n        if isinstance(fasta_type, str):\n            fasta_type = convert_str_to_fasta_type(fasta_type)\n        if custom_mapper is None:\n            mapper = PeptideMapper(\n                mapping_table_path=custom_mapping_path,\n                split_by=split_by,\n                split_index=split_index,\n                is_fasta=is_fasta,\n                fasta_type=fasta_type,\n            )\n        else:\n            mapper = custom_mapper\n        mapping_results = mapper.map_sequences(list(peptide_sequences))\n        for group in network.values():\n            group.a.mapped_proteins = mapping_results.peptide_to_protein[\n                group.a.sequence\n            ]\n            group.b.mapped_proteins = mapping_results.peptide_to_protein[\n                group.b.sequence\n            ]\n        return cls(network, omic_data)\n</code></pre>"},{"location":"API/lib/#xlranker.lib.XLDataSet.build_proteins","title":"<code>build_proteins(remove_intra=False)</code>","text":"<p>Build protein pairs of the XLDataSet network.</p> <p>Parameters:</p> Name Type Description Default <code>remove_intra</code> <code>bool</code> <p>if true, only creates protein pairs between different proteins. Defaults to True.</p> <code>False</code> Source code in <code>src/xlranker/lib.py</code> <pre><code>def build_proteins(self, remove_intra: bool = False) -&gt; None:\n    \"\"\"Build protein pairs of the XLDataSet network.\n\n    Args:\n        remove_intra (bool, optional): if true, only creates protein pairs between different proteins. Defaults to True.\n\n    \"\"\"\n    all_proteins: set[str] = set()\n    for p_peptide_pairs in self.peptide_pairs.values():\n        all_proteins = all_proteins.union(set(p_peptide_pairs.a.mapped_proteins))\n        all_proteins = all_proteins.union(set(p_peptide_pairs.b.mapped_proteins))\n    for protein in all_proteins:\n        abundances = {}\n        for omic_file in self.omic_data:\n            abundances[omic_file] = get_abundance(\n                self.omic_data[omic_file], protein\n            )\n        self.proteins[protein] = Protein(protein, protein, abundances)\n    remove_pairs = []\n    for (\n        peptide_pair_key\n    ) in self.peptide_pairs.keys():  # TODO: Make this loop cleaner to read\n        peptide_pair = self.peptide_pairs[peptide_pair_key]\n        peptide_pair_id = get_pair_id(peptide_pair.a, peptide_pair.b)\n        had_intra = False\n        for protein_a_name in peptide_pair.a.mapped_proteins:\n            for protein_b_name in peptide_pair.b.mapped_proteins:\n                if remove_intra and protein_a_name == protein_b_name:\n                    had_intra = True\n                    break\n        if had_intra:\n            remove_pairs.append(peptide_pair_key)\n        else:\n            for protein_a_name in peptide_pair.a.mapped_proteins:\n                protein_a = self.proteins[protein_a_name]\n                for protein_b_name in peptide_pair.b.mapped_proteins:\n                    protein_b = self.proteins[protein_b_name]\n                    protein_pair_id = get_pair_id(protein_a, protein_b)\n                    if protein_pair_id not in self.protein_pairs:\n                        new_pair = ProteinPair(protein_a, protein_b)\n                        self.protein_pairs[protein_pair_id] = new_pair\n                        peptide_pair.add_connection(protein_pair_id)\n                        new_pair.add_connection(peptide_pair_id)\n                    else:\n                        self.protein_pairs[protein_pair_id].add_connection(\n                            peptide_pair_id\n                        )\n                        peptide_pair.add_connection(protein_pair_id)\n    for key in remove_pairs:\n        self.peptide_pairs.pop(key)\n</code></pre>"},{"location":"API/lib/#xlranker.lib.XLDataSet.load_from_network","title":"<code>load_from_network(network_path, omics_data_folder, custom_mapper=None, custom_mapping_path=None, is_fasta=True, split_by='|', split_index=3, fasta_type='UNIPROT')</code>  <code>classmethod</code>","text":"<p>Create a XLDataSet object from a network file.</p> <p>Parameters:</p> Name Type Description Default <code>network_path</code> <code>str</code> <p>path to the peptide pairs</p> required <code>omics_data_folder</code> <code>str</code> <p>folder containing the omic data</p> required <code>custom_mapper</code> <code>PeptideMapper | None</code> <p>PeptideMapper object that should be used for mapping. If None, create peptide mapper using other parameters. Defaults to None.</p> <code>None</code> <code>custom_mapping_path</code> <code>str | None</code> <p>description. Defaults to None.</p> <code>None</code> <code>is_fasta</code> <code>bool</code> <p>description. Defaults to True.</p> <code>True</code> <code>split_by</code> <code>str | None</code> <p>description. Defaults to \"|\".</p> <code>'|'</code> <code>split_index</code> <code>int | None</code> <p>description. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Name Type Description <code>XLDataSet</code> <code>XLDataSet</code> <p>XLDataSet with peptide pairs and omics data loaded</p> Source code in <code>src/xlranker/lib.py</code> <pre><code>@classmethod\ndef load_from_network(\n    cls,\n    network_path: str,\n    omics_data_folder: str,\n    custom_mapper: PeptideMapper | None = None,\n    custom_mapping_path: str | None = None,\n    is_fasta: bool = True,\n    split_by: str | None = \"|\",\n    split_index: int | None = 3,\n    fasta_type: str | FastaType = \"UNIPROT\",\n) -&gt; \"XLDataSet\":\n    \"\"\"Create a XLDataSet object from a network file.\n\n    Args:\n        network_path (str): path to the peptide pairs\n        omics_data_folder (str): folder containing the omic data\n        custom_mapper (PeptideMapper | None, optional): PeptideMapper object that should be used for mapping. If None, create peptide mapper using other parameters. Defaults to None.\n        custom_mapping_path (str | None, optional): _description_. Defaults to None.\n        is_fasta (bool, optional): _description_. Defaults to True.\n        split_by (str | None, optional): _description_. Defaults to \"|\".\n        split_index (int | None, optional): _description_. Defaults to 3.\n\n    Returns:\n        XLDataSet: XLDataSet with peptide pairs and omics data loaded\n\n    \"\"\"\n    split_by = \"|\" if split_by is None else split_by\n    split_index = 6 if split_index is None else split_index\n    network = read_network_file(network_path)\n    omic_data: dict[str, pl.DataFrame] = read_data_folder(omics_data_folder)\n    peptide_sequences = set()\n    for group in network.values():\n        peptide_sequences.add(group.a.sequence)\n        peptide_sequences.add(group.b.sequence)\n    if isinstance(fasta_type, str):\n        fasta_type = convert_str_to_fasta_type(fasta_type)\n    if custom_mapper is None:\n        mapper = PeptideMapper(\n            mapping_table_path=custom_mapping_path,\n            split_by=split_by,\n            split_index=split_index,\n            is_fasta=is_fasta,\n            fasta_type=fasta_type,\n        )\n    else:\n        mapper = custom_mapper\n    mapping_results = mapper.map_sequences(list(peptide_sequences))\n    for group in network.values():\n        group.a.mapped_proteins = mapping_results.peptide_to_protein[\n            group.a.sequence\n        ]\n        group.b.mapped_proteins = mapping_results.peptide_to_protein[\n            group.b.sequence\n        ]\n    return cls(network, omic_data)\n</code></pre>"},{"location":"API/pipeline/","title":"Pipeline","text":"<p>Pipeline helper functions</p>"},{"location":"API/pipeline/#xlranker.pipeline.parsimony_only","title":"<code>parsimony_only(data_set, full_prioritization=False)</code>","text":"<p>Run the XLRanker pipeline with only the parsimonious selection step.</p> <p>This will likely result in many PARSIMONY_AMBIGUOUS protein pairs. To avoid ambiguity, you can set full_prioritization to True. This will select one random pair as the representative pair for ambiguous groups.</p> <p>Parameters:</p> Name Type Description Default <code>data_set</code> <code>XLDataSet</code> <p>Cross-linking dataset that needs prioritization</p> required <code>full_prioritization</code> <code>bool</code> <p>Default to False. If True, randomly select representative pairs for ambiguous groups.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>XLDataSet</code> <code>XLDataSet</code> <p>XLDataSet with only parsimonious selection performed.</p> Source code in <code>src/xlranker/pipeline.py</code> <pre><code>def parsimony_only(data_set: XLDataSet, full_prioritization: bool = False) -&gt; XLDataSet:\n    \"\"\"Run the XLRanker pipeline with only the parsimonious selection step.\n\n    This will likely result in many PARSIMONY_AMBIGUOUS protein pairs. To avoid ambiguity, you can set full_prioritization to True. This will select one random pair as the representative pair for ambiguous groups.\n\n    Args:\n        data_set (XLDataSet): Cross-linking dataset that needs prioritization\n        full_prioritization (bool): Default to False. If True, randomly select representative pairs for ambiguous groups.\n\n    Returns:\n        XLDataSet: XLDataSet with only parsimonious selection performed.\n\n    \"\"\"\n    data_set.build_proteins()  # TODO: Determine if this should be done when loaded/initialized\n    parsimony = ParsimonySelector(data_set)\n    parsimony.run()\n    if full_prioritization:\n        select_random(data_set)\n    return data_set\n</code></pre>"},{"location":"API/pipeline/#xlranker.pipeline.run_full_pipeline","title":"<code>run_full_pipeline(data_set, threshold=0.5)</code>","text":"<p>Run the full XLRanker pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>data_set</code> <code>XLDataSet</code> <p>Cross-linking dataset that needs prioritization</p> required <code>threshold</code> <code>float</code> <p>Score threshold for the expanded report</p> <code>0.5</code> <p>Returns:</p> Name Type Description <code>XLDataSet</code> <code>XLDataSet</code> <p>XLDataSet with full prioritization</p> Source code in <code>src/xlranker/pipeline.py</code> <pre><code>def run_full_pipeline(data_set: XLDataSet, threshold: float = 0.5) -&gt; XLDataSet:\n    \"\"\"Run the full XLRanker pipeline.\n\n    Args:\n        data_set (XLDataSet): Cross-linking dataset that needs prioritization\n        threshold (float): Score threshold for the expanded report\n\n    Returns:\n        XLDataSet: XLDataSet with full prioritization\n\n    \"\"\"\n    data_set.build_proteins()  # TODO: Determine if this should be done when loaded/initialized\n    parsimony = ParsimonySelector(data_set)\n    parsimony.run()\n    model = PrioritizationModel(data_set)\n    model.run_model()\n    get_final_network(data_set, ThresholdSelector(threshold))\n    make_all_reports(data_set.protein_pairs.values())\n    return data_set\n</code></pre>"},{"location":"API/bio/pairs/","title":"Pairs","text":""},{"location":"API/bio/pairs/#xlranker.bio.pairs.GroupedEntity","title":"<code>GroupedEntity</code>","text":"Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>class GroupedEntity:\n    group_id: int\n    subgroup_id: int\n    in_group: bool\n    prioritization_status: PrioritizationStatus\n    connections: set[str]\n\n    def __init__(self) -&gt; None:\n        self.in_group = False\n        self.group_id = -1\n        self.subgroup_id = 0\n        self.prioritization_status = PrioritizationStatus.NOT_ANALYZED\n        self.connections = set()\n\n    def set_group(self, group_id: int) -&gt; None:\n        self.in_group = True\n        self.group_id = group_id\n\n    def set_subgroup(self, subgroup_id: int) -&gt; None:\n        self.subgroup_id = subgroup_id\n\n    def get_group_string(self) -&gt; str:\n        return f\"{self.group_id}.{self.subgroup_id}\"\n\n    def get_group(self) -&gt; int:\n        return self.group_id\n\n    def set_prioritization_status(self, status: PrioritizationStatus) -&gt; None:\n        self.prioritization_status = status\n\n    def add_connection(self, entity: str) -&gt; None:\n        self.connections.add(entity)\n\n    def remove_connections(self, entities: set) -&gt; None:\n        self.connections.difference_update(entities)\n\n    def n_connections(self) -&gt; int:\n        return len(self.connections)\n\n    def overlap(self, entities: set[str]) -&gt; int:\n        return len(self.connections.intersection(entities))\n\n    def same_connectivity(self, grouped_entity: \"GroupedEntity\") -&gt; bool:\n        return (\n            len(self.connections.symmetric_difference(grouped_entity.connections)) == 0\n        )\n\n    def connectivity_id(self) -&gt; str:\n        \"\"\"Returns a unique, order-independent id for the set of connections.\"\"\"\n        return \"|\".join(sorted(self.connections))\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.GroupedEntity.connectivity_id","title":"<code>connectivity_id()</code>","text":"<p>Returns a unique, order-independent id for the set of connections.</p> Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>def connectivity_id(self) -&gt; str:\n    \"\"\"Returns a unique, order-independent id for the set of connections.\"\"\"\n    return \"|\".join(sorted(self.connections))\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.PeptidePair","title":"<code>PeptidePair</code>","text":"<p>               Bases: <code>GroupedEntity</code></p> <p>Peptide group that can contain multiple ProteinPairs and PeptidePairs.</p> Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>class PeptidePair(GroupedEntity):\n    \"\"\"Peptide group that can contain multiple ProteinPairs and PeptidePairs.\"\"\"\n\n    a: Peptide\n    b: Peptide\n    pair_id: str\n\n    def __init__(self, peptide_a: Peptide, peptide_b: Peptide) -&gt; None:\n        super().__init__()\n        self.a = peptide_a\n        self.b = peptide_b\n        self.pair_id = get_pair_id(peptide_a, peptide_b)\n\n    def __hash__(self) -&gt; int:\n        return hash(self.pair_id)\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.ProteinPair","title":"<code>ProteinPair</code>","text":"<p>               Bases: <code>GroupedEntity</code></p> <p>ProteinPair class that tracks the required data for the pipeline</p> Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>class ProteinPair(GroupedEntity):\n    \"\"\"ProteinPair class that tracks the required data for the pipeline\"\"\"\n\n    a: Protein\n    b: Protein\n    score: float\n    is_selected: bool\n    pair_id: str\n    is_intra: bool\n    report_status: ReportStatus\n\n    def __init__(self, protein_a: Protein, protein_b: Protein) -&gt; None:\n        \"\"\"Initialize a ProteinPair object, making sure a is the higher abundant protein. Input order does not matter.\n\n        Args:\n            protein_a (Protein): First protein in the pair\n            protein_b (Protein): Second protein in the pair\n\n        \"\"\"\n        super().__init__()\n        (a, b) = sort_proteins(protein_a, protein_b)\n        self.a = a\n        self.b = b\n        self.score = -1\n        self.is_selected = False\n        self.pair_id = get_pair_id(a, b)\n        self.is_intra = a == b\n        self.report_status = ReportStatus.NONE\n\n    def set_score(self, score: float) -&gt; None:\n        \"\"\"Set the score of the protein pair.\n\n        Args:\n            score (float): float of the score given to the pair\n\n        \"\"\"\n        self.score = score\n\n    def set_report_status(self, status: ReportStatus) -&gt; None:\n        \"\"\"Set the report status of the protein pair.\n\n        Args:\n            status (ReportStatus): ReportStatus enum value to set the pair to\n\n        \"\"\"\n        self.report_status = status\n\n    def select(self):\n        \"\"\"Set this pair to be selected\"\"\"\n        self.is_selected = True\n\n    def __eq__(self, value) -&gt; bool:\n        \"\"\"Checks if ProteinPairs are equivalent, without caring for order\n\n        Args:\n            value (Self): protein pair to compare to\n\n        Returns:\n            bool: True if protein pairs are equivalent, regardless of a and b order\n        \"\"\"\n        if value.__class__ != self.__class__:\n            return False\n        if self.a == value.a:\n            return self.b == value.b\n        elif self.a == value.b:\n            return self.b == value.a\n        return False\n\n    def abundance_dict(self) -&gt; dict[str, str | float | None]:\n        \"\"\"convert ProteinPair into dictionary of abundances, making abundances ending in a being the larger value\n\n        Returns:\n            dict[str, float | None]: dictionary where keys are the abundance name and the values being the abundance value\n        \"\"\"\n        ret_val: dict[str, str | float | None] = {\"pair\": self.pair_id}\n        for abundance_key in self.a.abundances:\n            a = self.a.abundances[abundance_key]\n            b = self.b.abundances[abundance_key]\n            if safe_a_greater_or_equal_to_b(a, b):\n                ret_val[f\"{abundance_key}_a\"] = a\n                ret_val[f\"{abundance_key}_b\"] = b\n            else:  # make sure a is the larger value\n                ret_val[f\"{abundance_key}_a\"] = b\n                ret_val[f\"{abundance_key}_b\"] = a\n        return ret_val\n\n    def to_tsv(self) -&gt; str:\n        \"\"\"converts object into a TSV string\n\n        Returns:\n            str: TSV representation of the protein pair, including id and status\n        \"\"\"\n        return f\"{self.pair_id}\\t{self.report_status}\\t{self.prioritization_status}\\t{self.get_group_string()}\"\n\n    def __hash__(self) -&gt; int:\n        return hash(self.pair_id)\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.ProteinPair.__eq__","title":"<code>__eq__(value)</code>","text":"<p>Checks if ProteinPairs are equivalent, without caring for order</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Self</code> <p>protein pair to compare to</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if protein pairs are equivalent, regardless of a and b order</p> Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>def __eq__(self, value) -&gt; bool:\n    \"\"\"Checks if ProteinPairs are equivalent, without caring for order\n\n    Args:\n        value (Self): protein pair to compare to\n\n    Returns:\n        bool: True if protein pairs are equivalent, regardless of a and b order\n    \"\"\"\n    if value.__class__ != self.__class__:\n        return False\n    if self.a == value.a:\n        return self.b == value.b\n    elif self.a == value.b:\n        return self.b == value.a\n    return False\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.ProteinPair.__init__","title":"<code>__init__(protein_a, protein_b)</code>","text":"<p>Initialize a ProteinPair object, making sure a is the higher abundant protein. Input order does not matter.</p> <p>Parameters:</p> Name Type Description Default <code>protein_a</code> <code>Protein</code> <p>First protein in the pair</p> required <code>protein_b</code> <code>Protein</code> <p>Second protein in the pair</p> required Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>def __init__(self, protein_a: Protein, protein_b: Protein) -&gt; None:\n    \"\"\"Initialize a ProteinPair object, making sure a is the higher abundant protein. Input order does not matter.\n\n    Args:\n        protein_a (Protein): First protein in the pair\n        protein_b (Protein): Second protein in the pair\n\n    \"\"\"\n    super().__init__()\n    (a, b) = sort_proteins(protein_a, protein_b)\n    self.a = a\n    self.b = b\n    self.score = -1\n    self.is_selected = False\n    self.pair_id = get_pair_id(a, b)\n    self.is_intra = a == b\n    self.report_status = ReportStatus.NONE\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.ProteinPair.abundance_dict","title":"<code>abundance_dict()</code>","text":"<p>convert ProteinPair into dictionary of abundances, making abundances ending in a being the larger value</p> <p>Returns:</p> Type Description <code>dict[str, str | float | None]</code> <p>dict[str, float | None]: dictionary where keys are the abundance name and the values being the abundance value</p> Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>def abundance_dict(self) -&gt; dict[str, str | float | None]:\n    \"\"\"convert ProteinPair into dictionary of abundances, making abundances ending in a being the larger value\n\n    Returns:\n        dict[str, float | None]: dictionary where keys are the abundance name and the values being the abundance value\n    \"\"\"\n    ret_val: dict[str, str | float | None] = {\"pair\": self.pair_id}\n    for abundance_key in self.a.abundances:\n        a = self.a.abundances[abundance_key]\n        b = self.b.abundances[abundance_key]\n        if safe_a_greater_or_equal_to_b(a, b):\n            ret_val[f\"{abundance_key}_a\"] = a\n            ret_val[f\"{abundance_key}_b\"] = b\n        else:  # make sure a is the larger value\n            ret_val[f\"{abundance_key}_a\"] = b\n            ret_val[f\"{abundance_key}_b\"] = a\n    return ret_val\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.ProteinPair.select","title":"<code>select()</code>","text":"<p>Set this pair to be selected</p> Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>def select(self):\n    \"\"\"Set this pair to be selected\"\"\"\n    self.is_selected = True\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.ProteinPair.set_report_status","title":"<code>set_report_status(status)</code>","text":"<p>Set the report status of the protein pair.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>ReportStatus</code> <p>ReportStatus enum value to set the pair to</p> required Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>def set_report_status(self, status: ReportStatus) -&gt; None:\n    \"\"\"Set the report status of the protein pair.\n\n    Args:\n        status (ReportStatus): ReportStatus enum value to set the pair to\n\n    \"\"\"\n    self.report_status = status\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.ProteinPair.set_score","title":"<code>set_score(score)</code>","text":"<p>Set the score of the protein pair.</p> <p>Parameters:</p> Name Type Description Default <code>score</code> <code>float</code> <p>float of the score given to the pair</p> required Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>def set_score(self, score: float) -&gt; None:\n    \"\"\"Set the score of the protein pair.\n\n    Args:\n        score (float): float of the score given to the pair\n\n    \"\"\"\n    self.score = score\n</code></pre>"},{"location":"API/bio/pairs/#xlranker.bio.pairs.ProteinPair.to_tsv","title":"<code>to_tsv()</code>","text":"<p>converts object into a TSV string</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>TSV representation of the protein pair, including id and status</p> Source code in <code>src/xlranker/bio/pairs.py</code> <pre><code>def to_tsv(self) -&gt; str:\n    \"\"\"converts object into a TSV string\n\n    Returns:\n        str: TSV representation of the protein pair, including id and status\n    \"\"\"\n    return f\"{self.pair_id}\\t{self.report_status}\\t{self.prioritization_status}\\t{self.get_group_string()}\"\n</code></pre>"},{"location":"API/bio/peptide/","title":"Peptide","text":""},{"location":"API/bio/peptide/#xlranker.bio.peptide.Peptide","title":"<code>Peptide</code>  <code>dataclass</code>","text":"<p>Peptide sequence object</p> <p>Attributes:</p> Name Type Description <code>sequence</code> <code>str</code> <p>Peptide sequence from peptide network</p> <code>mapped_proteins</code> <code>list[str]</code> <p>list of all proteins mapping to sequence</p> Source code in <code>src/xlranker/bio/peptide.py</code> <pre><code>@dataclass\nclass Peptide:\n    \"\"\"Peptide sequence object\n\n    Attributes:\n        sequence (str): Peptide sequence from peptide network\n        mapped_proteins (list[str]): list of all proteins mapping to sequence\n\n    \"\"\"\n\n    sequence: str\n    mapped_proteins: list[str]\n\n    def __init__(self, sequence: str, mapped_proteins: list[str] = []):\n        self.sequence = sequence\n        self.mapped_proteins = mapped_proteins\n\n    def __str__(self) -&gt; str:\n        return self.sequence\n</code></pre>"},{"location":"API/bio/protein/","title":"Protein","text":""},{"location":"API/bio/protein/#xlranker.bio.protein.Protein","title":"<code>Protein</code>","text":"<p>Protein class that has the name and abundance for the protein</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the protein</p> <code>abundance</code> <code>float | None</code> <p>Abundance value of the protein</p> Source code in <code>src/xlranker/bio/protein.py</code> <pre><code>class Protein:\n    \"\"\"Protein class that has the name and abundance for the protein\n\n    Attributes:\n        name (str): Name of the protein\n        abundance (float | None): Abundance value of the protein\n\n    \"\"\"\n\n    name: str\n    abundances: dict[str, float | None]\n    main_column: str\n    protein_name: str\n\n    def __init__(\n        self,\n        name: str,\n        protein_name: str,\n        abundances: dict[str, float | None] = {},\n        main_column: str | None = None,\n    ):\n        self.name = name\n        self.protein_name = protein_name\n        self.abundances = abundances\n        if main_column is None:\n            self.main_column = next(iter(abundances))\n        else:\n            self.main_column = main_column\n\n    def __eq__(self, value) -&gt; bool:\n        if isinstance(value, Protein):\n            return value.protein_name == self.protein_name\n        return False\n\n    def __hash__(self) -&gt; int:\n        return hash(self.name)\n\n    def abundance(self) -&gt; float | None:\n        return self.abundances.get(self.main_column, None)\n</code></pre>"},{"location":"API/bio/protein/#xlranker.bio.protein.sort_proteins","title":"<code>sort_proteins(a, b)</code>","text":"<p>Takes into two Proteins and returns them so the first protein is higher abundant. Handles missing values.</p> <p>In the case of missing values for both proteins or equal values, the input order is maintained.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Protein</code> <p>first protein</p> required <code>b</code> <code>Protein</code> <p>second protein</p> required <p>Returns:</p> Type Description <code>tuple[Protein, Protein]</code> <p>tuple[Protein, Protein]: protein tuple where the first protein is the higher abundant protein</p> Source code in <code>src/xlranker/bio/protein.py</code> <pre><code>def sort_proteins(a: Protein, b: Protein) -&gt; tuple[Protein, Protein]:\n    \"\"\"Takes into two Proteins and returns them so the first protein is higher abundant. Handles missing values.\n\n    In the case of missing values for both proteins or equal values, the input order is maintained.\n\n    Args:\n        a (Protein): first protein\n        b (Protein): second protein\n\n    Returns:\n        tuple[Protein, Protein]: protein tuple where the first protein is the higher abundant protein\n\n    \"\"\"\n    a_abundance = a.abundance()\n    b_abundance = b.abundance()\n    if a_abundance is None:\n        if b_abundance is None:\n            return (a, b)\n        return (b, a)\n    if b_abundance is None:\n        return (a, b)\n    if b_abundance &lt;= a_abundance:\n        return (a, b)\n    return (b, a)\n</code></pre>"},{"location":"API/ml/models/","title":"Models","text":"<p>Model Process:</p> <ol> <li>Identify Positive Dataset<ul> <li>All representative pairs from parsimonious selection</li> </ul> </li> <li>Generate Negative Dataset<ul> <li>Random protein pairs that are not candidate pairs</li> </ul> </li> </ol>"},{"location":"API/ml/models/#xlranker.ml.models.ModelConfig","title":"<code>ModelConfig</code>","text":"Source code in <code>src/xlranker/ml/models.py</code> <pre><code>class ModelConfig:\n    runs: int\n    folds: int\n    xgb_params: dict[str, Any]\n\n    def __init__(\n        self,\n        runs: int = 10,\n        folds: int = 5,\n        xgb_params: dict[str, Any] = DEFAULT_XGB_PARAMS,\n    ):\n        \"\"\"Config for the prioritization model\n\n        Args:\n            runs (int, optional): the number of model runs. Defaults to 10.\n            folds (int, optional): number of folds per run. Defaults to 5.\n            xgb_params (dict[str, Any], optional): dictionary of parameters for the XGBoost model. Defaults to DEFAULT_XGB_PARAMS.\n\n        \"\"\"\n        self.runs = runs\n        self.folds = folds\n        self.xgb_params = xgb_params\n\n    def validate(self) -&gt; bool:\n        attrs = {\n            \"runs\": (int, lambda x: x &gt;= 1),\n            \"folds\": (int, lambda x: x &gt;= 1),\n            \"xgb_params\": (dict, None),\n        }\n        for attr, (typ, cond) in attrs.items():\n            value = getattr(self, attr, None)\n            if not isinstance(value, typ):\n                return False\n            if cond and not cond(value):\n                return False\n        return True\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.ModelConfig.__init__","title":"<code>__init__(runs=10, folds=5, xgb_params=DEFAULT_XGB_PARAMS)</code>","text":"<p>Config for the prioritization model</p> <p>Parameters:</p> Name Type Description Default <code>runs</code> <code>int</code> <p>the number of model runs. Defaults to 10.</p> <code>10</code> <code>folds</code> <code>int</code> <p>number of folds per run. Defaults to 5.</p> <code>5</code> <code>xgb_params</code> <code>dict[str, Any]</code> <p>dictionary of parameters for the XGBoost model. Defaults to DEFAULT_XGB_PARAMS.</p> <code>DEFAULT_XGB_PARAMS</code> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def __init__(\n    self,\n    runs: int = 10,\n    folds: int = 5,\n    xgb_params: dict[str, Any] = DEFAULT_XGB_PARAMS,\n):\n    \"\"\"Config for the prioritization model\n\n    Args:\n        runs (int, optional): the number of model runs. Defaults to 10.\n        folds (int, optional): number of folds per run. Defaults to 5.\n        xgb_params (dict[str, Any], optional): dictionary of parameters for the XGBoost model. Defaults to DEFAULT_XGB_PARAMS.\n\n    \"\"\"\n    self.runs = runs\n    self.folds = folds\n    self.xgb_params = xgb_params\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.PrioritizationModel","title":"<code>PrioritizationModel</code>","text":"Source code in <code>src/xlranker/ml/models.py</code> <pre><code>class PrioritizationModel:\n    positives: list[ProteinPair]\n    to_predict: list[ProteinPair]\n    dataset: XLDataSet\n    existing_pairs: set[Container[str]]\n    model_config: ModelConfig\n    n_features: int\n    gmts: list[list[set[str]]]\n    ppi_db: pl.DataFrame\n    default_ppi: bool\n    xgboost_model: xgboost.XGBClassifier\n    pair_selector: PairSelector\n\n    def __init__(\n        self,\n        dataset: XLDataSet,\n        model_config: ModelConfig | None = None,\n        gmt_list: list[list[set[str]]] | None = None,\n        ppi_db: pl.DataFrame | None = None,\n        pair_selector: PairSelector = BestSelector(with_secondary=False),\n    ):\n        \"\"\"Initialize PrioritizationModel\n\n        Args:\n            dataset (XLDataSet): XL data set that needs prioritization. Requires Parsimony Analysis to have been performed.\n            model_config (ModelConfig | None, optional): Config for the model. If None use defaults. Defaults to None.\n            gmt_list (list[list[set[str]]] | None, optional): list of exclusive sets. Negative pairs can't be in the same set. Defaults to None.\n            ppi_db (pl.DataFrame | None, optional): PPI database. Should have two columns P1 and P2, where P1 is first alphabetically. Defaults to None.\n            pair_selector (PairSelector,  optional): Pair selector\n        \"\"\"\n        self.dataset = dataset\n        self.positives = []\n        self.to_predict = []\n        for protein_pair in self.dataset.protein_pairs.values():\n            match protein_pair.prioritization_status:\n                case PrioritizationStatus.PARSIMONY_PRIMARY_SELECTED:\n                    if protein_pair.a.name != protein_pair.b.name:\n                        self.positives.append(protein_pair)\n                case PrioritizationStatus.PARSIMONY_AMBIGUOUS:\n                    self.to_predict.append(protein_pair)\n        self.existing_pairs = set(\n            tuple(sorted([p.a.name, p.b.name]))\n            for p in self.dataset.protein_pairs.values()\n        )\n        self.n_features = len(self.to_predict[0].abundance_dict()) - 1\n        if model_config is None:\n            model_config = ModelConfig()\n        self.model_config = model_config\n        if gmt_list is None:\n            gmt_list = load_gmts()\n        self.gmts = gmt_list\n        if ppi_db is None:\n            self.default_ppi = True\n            ppi_db = load_default_ppi()\n        self.ppi_db = ppi_db\n        self.pair_selector = pair_selector\n\n    def is_intra(self, a: str, b: str) -&gt; float:\n        if config.human_only:  # Capitalize to ensure consistent case\n            a = a.upper()\n            b = b.upper()\n        if a == b:\n            return 1.0\n        return 0.0\n\n    def is_ppi(self, a: str, b: str) -&gt; float:\n        \"\"\"Determine if protein a and protein b has a known ppi in  ppi_db.\n\n        Order of `a` and `b` does not matter.\n\n        Args:\n            a (str): First protein\n            b (str): Second protein\n\n        Returns:\n            float: Return float with 1.0 meaning there is a known ppi in the db\n\n        \"\"\"\n        if config.human_only:  # Capitalize to ensure consistent case\n            a = a.upper()\n            b = b.upper()\n        if a &gt; b:\n            c = a\n            a = b\n            b = c\n        row_exists = self.ppi_db.filter(\n            (self.ppi_db[\"P1\"] == a) &amp; (self.ppi_db[\"P2\"] == b)\n        )\n        return 1.0 if row_exists.height &gt; 0 else 0.0\n\n    def get_negatives(self, n: int) -&gt; list[ProteinPair]:\n        \"\"\"Get a list of negative protein pairs.\n\n        Args:\n            n (int): the number of pairs to generate\n\n        Raises:\n            ValueError: Raised if the value of `n` is larger than what is possible\n                        and if config.fragile is True\n\n        Returns:\n            list[ProteinPair]: list of negative protein pairs\n\n        \"\"\"\n        negatives: list[ProteinPair] = []\n        n_prot = len(self.dataset.proteins.values())\n        if n &gt; (n_prot * (n_prot - 1)) // 2 - len(self.positives):\n            msg = f\"n value for get_negatives ({n}) is too large. Setting to maximum value: {(n_prot * (n_prot - 1)) // 2 - len(self.positives)}\"\n            if config.fragile:\n                logger.error(msg)\n                raise ValueError(\n                    \"get_negatives(n: int) n value is too large and fragile is True\"\n                )\n            logger.warning(msg)\n            n = (n_prot * (n_prot - 1)) // 2 - len(self.positives)\n        protein_ids = list(self.dataset.proteins.keys())\n\n        generated: set[Container[str]] = set()\n\n        while len(negatives) &lt; n:\n            a, b = random.sample(protein_ids, 2)\n            pair_key = tuple(sorted([a, b]))\n            if (\n                pair_key in self.existing_pairs\n                or pair_key in generated\n                or in_same_set(a, b, self.gmts)\n            ):\n                continue\n            negatives.append(\n                ProteinPair(self.dataset.proteins[a], self.dataset.proteins[b])\n            )\n            generated.add(pair_key)\n        return negatives\n\n    def construct_df_from_pairs(\n        self, pair_list: list[ProteinPair], has_label: bool, label_value: float = 0.0\n    ) -&gt; pl.DataFrame:\n        \"\"\"Construct a DataFrame from the list of Protein Pairs\n\n        Args:\n            pair_list (list[ProteinPair]): list of protein pairs to get the dataframe from\n            has_label (bool): if True, adds label column to dataframe\n            label_value (float, optional): value assigned to the label column. Defaults to 0.0 (negative).\n\n        Returns:\n            pl.DataFrame: DataFrame object with the first column being the pair ID, following columns with abundances for the proteins. If `has_label` is true, last column is label with a value of `label_value`.\n\n        \"\"\"\n        df_array: list[dict[str, str | int | float | None]] = []\n        is_first = True\n        headers = [\"pair\"]  # headers in the correct order\n        schema: dict[str, pl.DataType] = {\"pair\": pl.String()}\n        for pair in pair_list:\n            pair_dict = pair.abundance_dict()\n            if (\n                config.human_only or not self.default_ppi\n            ):  # Can only add if only human or if using custom PPI DB\n                pair_dict[\"is_ppi\"] = self.is_ppi(pair.a.name, pair.b.name)\n                # pair_dict[\"is_intra\"] = self.is_intra(pair.a.name, pair.b.name)\n            if has_label:\n                pair_dict[\"label\"] = label_value\n            df_array.append(pair_dict)\n            if is_first:\n                is_first = False\n                for header in pair_dict.keys():\n                    if \"pair\" != header:\n                        headers.append(header)\n                        schema[header] = pl.Float64()\n        return pl.DataFrame(df_array, schema=pl.Schema(schema)).select(headers)\n\n    def construct_predict_df(self) -&gt; pl.DataFrame:\n        return self.construct_df_from_pairs(self.to_predict, has_label=False)\n\n    def construct_training_df(self, negative_pairs: list[ProteinPair]) -&gt; pl.DataFrame:\n        \"\"\"Generate a Polars DataFrame from the positive pairs and a list of negative ProteinPair.\n\n        Args:\n            negative_pairs (list[ProteinPair]): the list of negative pairs to add to DataFrame\n\n        Returns:\n            pl.DataFrame: DataFrame where the first column is 'pair', followed by abundances. Last column is 'label'\n\n        \"\"\"\n        positive_df = self.construct_df_from_pairs(\n            self.positives, has_label=True, label_value=1.0\n        )\n        negative_df = self.construct_df_from_pairs(\n            negative_pairs, has_label=True, label_value=0.0\n        )\n        return pl.concat([positive_df, negative_df])\n\n    def run_model(self):\n        \"\"\"Run the model and get predictions for all protein pairs.\"\"\"\n\n        random_seed = random.random() * 100000\n\n        predict_df = self.construct_predict_df()\n\n        predict_X = predict_df.drop(\"pair\").to_numpy()\n\n        predictions = np.zeros((self.model_config.runs, len(self.to_predict)))\n\n        # Lists to store data for Shapley values and AUC plots\n        all_test_labels = []\n        all_test_preds = []\n        run_ids = []\n        aucs = []\n\n        for run in range(self.model_config.runs):\n            logger.info(f\"Model on run {run + 1}/{self.model_config.runs}\")\n            np.random.seed(int(random_seed + run))\n            train_df = self.construct_training_df(\n                self.get_negatives(len(self.positives))\n            )\n\n            X = train_df.drop([\"pair\", \"label\"]).to_numpy()\n            y = train_df.get_column(\"label\").to_numpy()\n\n            skf = StratifiedKFold(\n                n_splits=self.model_config.folds,\n                shuffle=True,\n                random_state=(int(random_seed + run)),\n            )\n\n            y_test_run = np.array([])\n            y_test_pred_run = np.array([])\n\n            # Run k-fold cross-validation\n            for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n                # Split data\n                X_train, X_test = X[train_idx], X[test_idx]\n                y_train, y_test = y[train_idx], y[test_idx]\n\n                model = xgboost.XGBClassifier(\n                    **self.model_config.xgb_params,\n                    random_state=int(random_seed + run * fold),\n                )\n\n                _ = model.fit(X_train, y_train)\n\n                y_test_pred = model.predict_proba(X_test)[:, 1]\n\n                y_test_run = np.append(y_test_run, y_test)\n                y_test_pred_run = np.append(y_test_pred_run, y_test_pred)\n\n            # Train a model on the entire dataset for predictions\n            random_seed = random.random() * 100000\n            model = xgboost.XGBClassifier(\n                **self.model_config.xgb_params, random_state=int(random_seed)\n            )\n            model.fit(X, y)\n\n            # Get predictions for the prediction dataset\n            cur_predictions = model.predict_proba(predict_X)[:, 1]\n            predictions[run] = cur_predictions\n\n            auc_score = roc_auc_score(y_test_run, y_test_pred_run)\n            aucs.append(auc_score)\n            logger.info(f\"ROC AUC for run {run + 1}: {auc_score:.2f}\")\n            all_test_labels.append(y_test_run)\n            all_test_preds.append(y_test_pred_run)\n            run_ids.append(run)\n\n        mean_predictions = np.mean(predictions, axis=0)\n\n        for i, protein_pair in enumerate(self.to_predict):\n            protein_pair.set_score(mean_predictions[i])\n\n        os.makedirs(\n            config.output, exist_ok=True\n        )  # TODO: Have this done automatically or ask if its okay if exists.\n\n        predict_df = predict_df.with_columns(pl.Series(\"prediction\", mean_predictions))\n        predict_df.write_csv(\n            str(Path(config.output).joinpath(\"model_output.tsv\")), separator=\"\\t\"\n        )\n\n        # Print summary statistics\n        logger.info(\n            f\"Average AUC across {self.model_config.runs} runs: {np.mean(aucs):.4f} \u00b1 {np.std(aucs):.4f}\"\n        )\n        logger.info(\"Results saved to: .\")  # TODO Have output directory be configurable\n\n    def get_selected(self) -&gt; list[ProteinPair]:\n        \"\"\"Get all `ProteinPair`s that were accepted\n\n        Returns:\n            list[ProteinPair]: All machine-learning selected pairs predicted by this model\n\n        \"\"\"\n        return [\n            p\n            for p in self.to_predict\n            if p.prioritization_status == PrioritizationStatus.ML_PRIMARY_SELECTED\n            or p.prioritization_status == PrioritizationStatus.ML_SECONDARY_SELECTED\n        ]\n\n    def get_selections(self) -&gt; list[ProteinPair]:\n        \"\"\"Get the best pair for each protein pair subgroup\n\n        Returns:\n            list[ProteinPair]: list of the protein pairs that were accepted\n\n        \"\"\"\n        self.pair_selector.process(self.to_predict)\n        return self.get_selected()\n\n    def save_model(self, file_path: str) -&gt; None:\n        self.xgboost_model.save_model(file_path)\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.PrioritizationModel.__init__","title":"<code>__init__(dataset, model_config=None, gmt_list=None, ppi_db=None, pair_selector=BestSelector(with_secondary=False))</code>","text":"<p>Initialize PrioritizationModel</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>XLDataSet</code> <p>XL data set that needs prioritization. Requires Parsimony Analysis to have been performed.</p> required <code>model_config</code> <code>ModelConfig | None</code> <p>Config for the model. If None use defaults. Defaults to None.</p> <code>None</code> <code>gmt_list</code> <code>list[list[set[str]]] | None</code> <p>list of exclusive sets. Negative pairs can't be in the same set. Defaults to None.</p> <code>None</code> <code>ppi_db</code> <code>DataFrame | None</code> <p>PPI database. Should have two columns P1 and P2, where P1 is first alphabetically. Defaults to None.</p> <code>None</code> <code>pair_selector</code> <code>(PairSelector, optional)</code> <p>Pair selector</p> <code>BestSelector(with_secondary=False)</code> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def __init__(\n    self,\n    dataset: XLDataSet,\n    model_config: ModelConfig | None = None,\n    gmt_list: list[list[set[str]]] | None = None,\n    ppi_db: pl.DataFrame | None = None,\n    pair_selector: PairSelector = BestSelector(with_secondary=False),\n):\n    \"\"\"Initialize PrioritizationModel\n\n    Args:\n        dataset (XLDataSet): XL data set that needs prioritization. Requires Parsimony Analysis to have been performed.\n        model_config (ModelConfig | None, optional): Config for the model. If None use defaults. Defaults to None.\n        gmt_list (list[list[set[str]]] | None, optional): list of exclusive sets. Negative pairs can't be in the same set. Defaults to None.\n        ppi_db (pl.DataFrame | None, optional): PPI database. Should have two columns P1 and P2, where P1 is first alphabetically. Defaults to None.\n        pair_selector (PairSelector,  optional): Pair selector\n    \"\"\"\n    self.dataset = dataset\n    self.positives = []\n    self.to_predict = []\n    for protein_pair in self.dataset.protein_pairs.values():\n        match protein_pair.prioritization_status:\n            case PrioritizationStatus.PARSIMONY_PRIMARY_SELECTED:\n                if protein_pair.a.name != protein_pair.b.name:\n                    self.positives.append(protein_pair)\n            case PrioritizationStatus.PARSIMONY_AMBIGUOUS:\n                self.to_predict.append(protein_pair)\n    self.existing_pairs = set(\n        tuple(sorted([p.a.name, p.b.name]))\n        for p in self.dataset.protein_pairs.values()\n    )\n    self.n_features = len(self.to_predict[0].abundance_dict()) - 1\n    if model_config is None:\n        model_config = ModelConfig()\n    self.model_config = model_config\n    if gmt_list is None:\n        gmt_list = load_gmts()\n    self.gmts = gmt_list\n    if ppi_db is None:\n        self.default_ppi = True\n        ppi_db = load_default_ppi()\n    self.ppi_db = ppi_db\n    self.pair_selector = pair_selector\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.PrioritizationModel.construct_df_from_pairs","title":"<code>construct_df_from_pairs(pair_list, has_label, label_value=0.0)</code>","text":"<p>Construct a DataFrame from the list of Protein Pairs</p> <p>Parameters:</p> Name Type Description Default <code>pair_list</code> <code>list[ProteinPair]</code> <p>list of protein pairs to get the dataframe from</p> required <code>has_label</code> <code>bool</code> <p>if True, adds label column to dataframe</p> required <code>label_value</code> <code>float</code> <p>value assigned to the label column. Defaults to 0.0 (negative).</p> <code>0.0</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: DataFrame object with the first column being the pair ID, following columns with abundances for the proteins. If <code>has_label</code> is true, last column is label with a value of <code>label_value</code>.</p> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def construct_df_from_pairs(\n    self, pair_list: list[ProteinPair], has_label: bool, label_value: float = 0.0\n) -&gt; pl.DataFrame:\n    \"\"\"Construct a DataFrame from the list of Protein Pairs\n\n    Args:\n        pair_list (list[ProteinPair]): list of protein pairs to get the dataframe from\n        has_label (bool): if True, adds label column to dataframe\n        label_value (float, optional): value assigned to the label column. Defaults to 0.0 (negative).\n\n    Returns:\n        pl.DataFrame: DataFrame object with the first column being the pair ID, following columns with abundances for the proteins. If `has_label` is true, last column is label with a value of `label_value`.\n\n    \"\"\"\n    df_array: list[dict[str, str | int | float | None]] = []\n    is_first = True\n    headers = [\"pair\"]  # headers in the correct order\n    schema: dict[str, pl.DataType] = {\"pair\": pl.String()}\n    for pair in pair_list:\n        pair_dict = pair.abundance_dict()\n        if (\n            config.human_only or not self.default_ppi\n        ):  # Can only add if only human or if using custom PPI DB\n            pair_dict[\"is_ppi\"] = self.is_ppi(pair.a.name, pair.b.name)\n            # pair_dict[\"is_intra\"] = self.is_intra(pair.a.name, pair.b.name)\n        if has_label:\n            pair_dict[\"label\"] = label_value\n        df_array.append(pair_dict)\n        if is_first:\n            is_first = False\n            for header in pair_dict.keys():\n                if \"pair\" != header:\n                    headers.append(header)\n                    schema[header] = pl.Float64()\n    return pl.DataFrame(df_array, schema=pl.Schema(schema)).select(headers)\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.PrioritizationModel.construct_training_df","title":"<code>construct_training_df(negative_pairs)</code>","text":"<p>Generate a Polars DataFrame from the positive pairs and a list of negative ProteinPair.</p> <p>Parameters:</p> Name Type Description Default <code>negative_pairs</code> <code>list[ProteinPair]</code> <p>the list of negative pairs to add to DataFrame</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: DataFrame where the first column is 'pair', followed by abundances. Last column is 'label'</p> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def construct_training_df(self, negative_pairs: list[ProteinPair]) -&gt; pl.DataFrame:\n    \"\"\"Generate a Polars DataFrame from the positive pairs and a list of negative ProteinPair.\n\n    Args:\n        negative_pairs (list[ProteinPair]): the list of negative pairs to add to DataFrame\n\n    Returns:\n        pl.DataFrame: DataFrame where the first column is 'pair', followed by abundances. Last column is 'label'\n\n    \"\"\"\n    positive_df = self.construct_df_from_pairs(\n        self.positives, has_label=True, label_value=1.0\n    )\n    negative_df = self.construct_df_from_pairs(\n        negative_pairs, has_label=True, label_value=0.0\n    )\n    return pl.concat([positive_df, negative_df])\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.PrioritizationModel.get_negatives","title":"<code>get_negatives(n)</code>","text":"<p>Get a list of negative protein pairs.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>the number of pairs to generate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised if the value of <code>n</code> is larger than what is possible         and if config.fragile is True</p> <p>Returns:</p> Type Description <code>list[ProteinPair]</code> <p>list[ProteinPair]: list of negative protein pairs</p> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def get_negatives(self, n: int) -&gt; list[ProteinPair]:\n    \"\"\"Get a list of negative protein pairs.\n\n    Args:\n        n (int): the number of pairs to generate\n\n    Raises:\n        ValueError: Raised if the value of `n` is larger than what is possible\n                    and if config.fragile is True\n\n    Returns:\n        list[ProteinPair]: list of negative protein pairs\n\n    \"\"\"\n    negatives: list[ProteinPair] = []\n    n_prot = len(self.dataset.proteins.values())\n    if n &gt; (n_prot * (n_prot - 1)) // 2 - len(self.positives):\n        msg = f\"n value for get_negatives ({n}) is too large. Setting to maximum value: {(n_prot * (n_prot - 1)) // 2 - len(self.positives)}\"\n        if config.fragile:\n            logger.error(msg)\n            raise ValueError(\n                \"get_negatives(n: int) n value is too large and fragile is True\"\n            )\n        logger.warning(msg)\n        n = (n_prot * (n_prot - 1)) // 2 - len(self.positives)\n    protein_ids = list(self.dataset.proteins.keys())\n\n    generated: set[Container[str]] = set()\n\n    while len(negatives) &lt; n:\n        a, b = random.sample(protein_ids, 2)\n        pair_key = tuple(sorted([a, b]))\n        if (\n            pair_key in self.existing_pairs\n            or pair_key in generated\n            or in_same_set(a, b, self.gmts)\n        ):\n            continue\n        negatives.append(\n            ProteinPair(self.dataset.proteins[a], self.dataset.proteins[b])\n        )\n        generated.add(pair_key)\n    return negatives\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.PrioritizationModel.get_selected","title":"<code>get_selected()</code>","text":"<p>Get all <code>ProteinPair</code>s that were accepted</p> <p>Returns:</p> Type Description <code>list[ProteinPair]</code> <p>list[ProteinPair]: All machine-learning selected pairs predicted by this model</p> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def get_selected(self) -&gt; list[ProteinPair]:\n    \"\"\"Get all `ProteinPair`s that were accepted\n\n    Returns:\n        list[ProteinPair]: All machine-learning selected pairs predicted by this model\n\n    \"\"\"\n    return [\n        p\n        for p in self.to_predict\n        if p.prioritization_status == PrioritizationStatus.ML_PRIMARY_SELECTED\n        or p.prioritization_status == PrioritizationStatus.ML_SECONDARY_SELECTED\n    ]\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.PrioritizationModel.get_selections","title":"<code>get_selections()</code>","text":"<p>Get the best pair for each protein pair subgroup</p> <p>Returns:</p> Type Description <code>list[ProteinPair]</code> <p>list[ProteinPair]: list of the protein pairs that were accepted</p> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def get_selections(self) -&gt; list[ProteinPair]:\n    \"\"\"Get the best pair for each protein pair subgroup\n\n    Returns:\n        list[ProteinPair]: list of the protein pairs that were accepted\n\n    \"\"\"\n    self.pair_selector.process(self.to_predict)\n    return self.get_selected()\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.PrioritizationModel.is_ppi","title":"<code>is_ppi(a, b)</code>","text":"<p>Determine if protein a and protein b has a known ppi in  ppi_db.</p> <p>Order of <code>a</code> and <code>b</code> does not matter.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>str</code> <p>First protein</p> required <code>b</code> <code>str</code> <p>Second protein</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Return float with 1.0 meaning there is a known ppi in the db</p> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def is_ppi(self, a: str, b: str) -&gt; float:\n    \"\"\"Determine if protein a and protein b has a known ppi in  ppi_db.\n\n    Order of `a` and `b` does not matter.\n\n    Args:\n        a (str): First protein\n        b (str): Second protein\n\n    Returns:\n        float: Return float with 1.0 meaning there is a known ppi in the db\n\n    \"\"\"\n    if config.human_only:  # Capitalize to ensure consistent case\n        a = a.upper()\n        b = b.upper()\n    if a &gt; b:\n        c = a\n        a = b\n        b = c\n    row_exists = self.ppi_db.filter(\n        (self.ppi_db[\"P1\"] == a) &amp; (self.ppi_db[\"P2\"] == b)\n    )\n    return 1.0 if row_exists.height &gt; 0 else 0.0\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.PrioritizationModel.run_model","title":"<code>run_model()</code>","text":"<p>Run the model and get predictions for all protein pairs.</p> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def run_model(self):\n    \"\"\"Run the model and get predictions for all protein pairs.\"\"\"\n\n    random_seed = random.random() * 100000\n\n    predict_df = self.construct_predict_df()\n\n    predict_X = predict_df.drop(\"pair\").to_numpy()\n\n    predictions = np.zeros((self.model_config.runs, len(self.to_predict)))\n\n    # Lists to store data for Shapley values and AUC plots\n    all_test_labels = []\n    all_test_preds = []\n    run_ids = []\n    aucs = []\n\n    for run in range(self.model_config.runs):\n        logger.info(f\"Model on run {run + 1}/{self.model_config.runs}\")\n        np.random.seed(int(random_seed + run))\n        train_df = self.construct_training_df(\n            self.get_negatives(len(self.positives))\n        )\n\n        X = train_df.drop([\"pair\", \"label\"]).to_numpy()\n        y = train_df.get_column(\"label\").to_numpy()\n\n        skf = StratifiedKFold(\n            n_splits=self.model_config.folds,\n            shuffle=True,\n            random_state=(int(random_seed + run)),\n        )\n\n        y_test_run = np.array([])\n        y_test_pred_run = np.array([])\n\n        # Run k-fold cross-validation\n        for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n            # Split data\n            X_train, X_test = X[train_idx], X[test_idx]\n            y_train, y_test = y[train_idx], y[test_idx]\n\n            model = xgboost.XGBClassifier(\n                **self.model_config.xgb_params,\n                random_state=int(random_seed + run * fold),\n            )\n\n            _ = model.fit(X_train, y_train)\n\n            y_test_pred = model.predict_proba(X_test)[:, 1]\n\n            y_test_run = np.append(y_test_run, y_test)\n            y_test_pred_run = np.append(y_test_pred_run, y_test_pred)\n\n        # Train a model on the entire dataset for predictions\n        random_seed = random.random() * 100000\n        model = xgboost.XGBClassifier(\n            **self.model_config.xgb_params, random_state=int(random_seed)\n        )\n        model.fit(X, y)\n\n        # Get predictions for the prediction dataset\n        cur_predictions = model.predict_proba(predict_X)[:, 1]\n        predictions[run] = cur_predictions\n\n        auc_score = roc_auc_score(y_test_run, y_test_pred_run)\n        aucs.append(auc_score)\n        logger.info(f\"ROC AUC for run {run + 1}: {auc_score:.2f}\")\n        all_test_labels.append(y_test_run)\n        all_test_preds.append(y_test_pred_run)\n        run_ids.append(run)\n\n    mean_predictions = np.mean(predictions, axis=0)\n\n    for i, protein_pair in enumerate(self.to_predict):\n        protein_pair.set_score(mean_predictions[i])\n\n    os.makedirs(\n        config.output, exist_ok=True\n    )  # TODO: Have this done automatically or ask if its okay if exists.\n\n    predict_df = predict_df.with_columns(pl.Series(\"prediction\", mean_predictions))\n    predict_df.write_csv(\n        str(Path(config.output).joinpath(\"model_output.tsv\")), separator=\"\\t\"\n    )\n\n    # Print summary statistics\n    logger.info(\n        f\"Average AUC across {self.model_config.runs} runs: {np.mean(aucs):.4f} \u00b1 {np.std(aucs):.4f}\"\n    )\n    logger.info(\"Results saved to: .\")  # TODO Have output directory be configurable\n</code></pre>"},{"location":"API/ml/models/#xlranker.ml.models.in_same_set","title":"<code>in_same_set(a, b, sets)</code>","text":"<p>Check if a and b are located in the same set in any of the exclusive sets provided</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>str</code> <p>entity a</p> required <code>b</code> <code>str</code> <p>entity b</p> required <code>sets</code> <code>list[list[set[str]]]</code> <p>list of gmts, which are lists of sets</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if a and b both located in at least one set</p> Source code in <code>src/xlranker/ml/models.py</code> <pre><code>def in_same_set(a: str, b: str, sets: list[list[set[str]]]) -&gt; bool:\n    \"\"\"Check if a and b are located in the same set in any of the exclusive sets provided\n\n    Args:\n        a (str): entity a\n        b (str): entity b\n        sets (list[list[set[str]]]): list of gmts, which are lists of sets\n\n    Returns:\n        bool: True if a and b both located in at least one set\n\n    \"\"\"\n    for gmt in sets:\n        for gene_set in gmt:\n            if a in gene_set and b in gene_set:\n                return True\n    return False\n</code></pre>"},{"location":"API/parsimony/prioritize/","title":"Prioritize","text":""},{"location":"API/parsimony/prioritize/#xlranker.parsimony.prioritize.ParsimonySelector","title":"<code>ParsimonySelector</code>","text":"Source code in <code>src/xlranker/parsimony/prioritize.py</code> <pre><code>class ParsimonySelector:\n    data_set: XLDataSet\n    protein_groups: dict[int, list[ProteinPair]]\n    peptide_groups: dict[int, list[PeptidePair]]\n    can_prioritize: bool\n\n    def __init__(self, data_set: XLDataSet):\n        \"\"\"Initialize the ParsimonySelector object\n\n        Args:\n            data_set (XLDataSet): cross-linking dataset\n        \"\"\"\n        self.data_set = data_set\n        self.protein_groups = {}\n        self.peptide_groups = {}\n        self.can_prioritize = False\n        self.network = None\n\n    def assign_protein_pair(self, protein_pair: ProteinPair, group_id: int) -&gt; None:\n        if protein_pair.in_group:\n            if protein_pair.group_id != group_id:\n                raise ValueError(\n                    f\"Protein Pair {protein_pair} has incorrect group id. Expected {group_id}. Got {protein_pair.group_id}.\"\n                )\n            return\n        protein_pair.set_group(group_id)\n        if group_id not in self.protein_groups:\n            self.protein_groups[group_id] = []\n        self.protein_groups[group_id].append(protein_pair)\n        for peptide_pair_id in protein_pair.connections:\n            self.assign_peptide_pair(\n                self.data_set.peptide_pairs[peptide_pair_id], group_id\n            )\n\n    def assign_peptide_pair(self, peptide_pair: PeptidePair, group_id: int) -&gt; None:\n        if peptide_pair.in_group:\n            if peptide_pair.group_id != group_id:\n                raise ValueError(\n                    f\"Protein Pair {peptide_pair} has incorrect group id. Expected {group_id}. Got {peptide_pair.group_id}.\"\n                )\n            return\n        peptide_pair.set_group(group_id)\n        if group_id not in self.peptide_groups:\n            self.peptide_groups[group_id] = []\n        self.peptide_groups[group_id].append(peptide_pair)\n        for protein_pair_id in peptide_pair.connections:\n            self.assign_protein_pair(\n                self.data_set.protein_pairs[protein_pair_id], group_id\n            )\n\n    def create_groups(self) -&gt; None:\n        next_group_id = 1\n        for pair in self.data_set.peptide_pairs.values():\n            if pair.in_group or len(pair.connections) == 0:\n                continue\n            self.assign_peptide_pair(pair, next_group_id)\n            next_group_id += 1\n        self.can_prioritize = True\n\n    def prioritize_group(self, group_id: int) -&gt; None:\n        peptide_names = set(\n            [get_pair_id(pep.a, pep.b) for pep in self.peptide_groups[group_id]]\n        )\n        proteins = set(self.protein_groups[group_id])\n        protein_pair_groups: dict[str, list[ProteinPair]] = {}\n        for protein_pair in proteins:\n            conn_id = protein_pair.connectivity_id()\n            if conn_id not in protein_pair_groups:\n                protein_pair_groups[conn_id] = []\n            protein_pair_groups[conn_id].append(protein_pair)\n        while len(peptide_names) &gt; 0:\n            max_connections = 0\n            best_pairs: set[str] = (\n                set()\n            )  # set so there is no bias towards larger groups\n            for conn_id in protein_pair_groups:\n                n_conn = protein_pair_groups[conn_id][0].overlap(peptide_names)\n                if max_connections &lt; n_conn:\n                    max_connections = n_conn\n                    best_pairs = set()\n                    best_pairs.add(conn_id)\n                elif max_connections == n_conn:\n                    best_pairs.add(conn_id)\n            selected_index = random.randint(\n                0, len(best_pairs) - 1\n            )  # select one random index to move forward\n            best_pair_group = protein_pair_groups[list(best_pairs)[selected_index]]\n            peptide_names.difference_update(best_pair_group[0].connections)\n            intra_pairs: list[ProteinPair] = []\n            # for pair in best_pair_group\n            status = (\n                PrioritizationStatus.PARSIMONY_PRIMARY_SELECTED\n                if len(best_pair_group) == 1\n                else PrioritizationStatus.PARSIMONY_AMBIGUOUS\n            )\n            for pair in best_pair_group:\n                if pair.is_intra and len(best_pair_group) &gt; 1:\n                    intra_pairs.append(pair)\n                else:\n                    pair.set_prioritization_status(status)\n                    if len(best_pair_group) == 1:\n                        pair.set_score(1.01)\n                        pair.set_report_status(\n                            ReportStatus.CONSERVATIVE\n                        )  # Unambiguous pairs are reported as CONSERVATIVE\n            if len(intra_pairs) &gt; 0:\n                intra_pairs.sort(\n                    key=lambda pair: (\n                        -pair.a.abundance()  # type: ignore\n                        if pair.a.abundance() is not None\n                        else float(\"-inf\"),\n                        pair.a.name,\n                    )\n                )\n                intra_pairs[0].set_prioritization_status(\n                    PrioritizationStatus.PARSIMONY_PRIMARY_SELECTED\n                )\n                intra_pairs[0].set_score(1.0 + 0.01 * len(intra_pairs))\n                intra_pairs[0].set_report_status(\n                    ReportStatus.MINIMAL\n                )  # Selected intra pairs are reported at least as MINIMAL\n                for i in range(1, len(intra_pairs)):\n                    intra_pairs[i].set_prioritization_status(\n                        PrioritizationStatus.PARSIMONY_NOT_SELECTED  # Not selected by default\n                    )\n                    intra_pairs[i].set_report_status(\n                        ReportStatus.EXPANDED\n                    )  # Secondary intra pairs are reported as EXPANDED\n                    intra_pairs[i].set_score(1.0 + 0.01 * (len(intra_pairs) - i))\n        for pair_group in protein_pair_groups.values():\n            for protein_pair in pair_group:\n                if (\n                    protein_pair.prioritization_status\n                    == PrioritizationStatus.NOT_ANALYZED\n                ):  # if not analyzed then pair is not selected\n                    protein_pair.set_prioritization_status(\n                        PrioritizationStatus.PARSIMONY_NOT_SELECTED\n                    )\n                    protein_pair.set_report_status(ReportStatus.ALL)\n\n    def prioritize(self) -&gt; None:\n        if not self.can_prioritize:\n            logger.warning(\n                \"Parsimony group creation not performed before prioritization. Running now.\"\n            )\n            self.create_groups()\n        for group in self.protein_groups:\n            self.prioritize_group(group)\n\n    def run(self) -&gt; None:\n        self.create_groups()\n        self.prioritize()\n</code></pre>"},{"location":"API/parsimony/prioritize/#xlranker.parsimony.prioritize.ParsimonySelector.__init__","title":"<code>__init__(data_set)</code>","text":"<p>Initialize the ParsimonySelector object</p> <p>Parameters:</p> Name Type Description Default <code>data_set</code> <code>XLDataSet</code> <p>cross-linking dataset</p> required Source code in <code>src/xlranker/parsimony/prioritize.py</code> <pre><code>def __init__(self, data_set: XLDataSet):\n    \"\"\"Initialize the ParsimonySelector object\n\n    Args:\n        data_set (XLDataSet): cross-linking dataset\n    \"\"\"\n    self.data_set = data_set\n    self.protein_groups = {}\n    self.peptide_groups = {}\n    self.can_prioritize = False\n    self.network = None\n</code></pre>"},{"location":"API/parsimony/prioritize/#xlranker.parsimony.prioritize.select_random","title":"<code>select_random(data_set)</code>","text":"<p>Resolve ambiguous groups by selected a random pair.</p> <p>This is normally done by the machine learning model. However, if training data is not available, use this function to resolve the remaining ambiguity.</p> <p>Parameters:</p> Name Type Description Default <code>data_set</code> <code>XLDataSet</code> <p>data set to resolve ambiguity</p> required Source code in <code>src/xlranker/parsimony/prioritize.py</code> <pre><code>def select_random(\n    data_set: XLDataSet,\n) -&gt; None:  # FIXME: This needs to be updated to handle the selection process\n    \"\"\"Resolve ambiguous groups by selected a random pair.\n\n    This is normally done by the machine learning model. However, if training data is not available, use this function to resolve the remaining ambiguity.\n\n    Args:\n        data_set (XLDataSet): data set to resolve ambiguity\n\n    \"\"\"\n    ambiguity: dict[str, list[ProteinPair]] = {}\n    for pair in data_set.protein_pairs.values():\n        if pair.prioritization_status != PrioritizationStatus.PARSIMONY_AMBIGUOUS:\n            continue  # No ambiguity\n        conn_id = pair.connectivity_id()\n        if conn_id not in ambiguity:\n            ambiguity[conn_id] = []\n        ambiguity[conn_id].append(pair)\n    for conn_id in ambiguity:\n        selected_location = random.randrange(len(ambiguity[conn_id]))\n        for i in range(len(ambiguity[conn_id])):\n            if selected_location == i:\n                ambiguity[conn_id][i].set_prioritization_status(\n                    PrioritizationStatus.PARSIMONY_PRIMARY_SELECTED\n                )\n            else:\n                ambiguity[conn_id][i].set_prioritization_status(\n                    PrioritizationStatus.PARSIMONY_NOT_SELECTED\n                )\n</code></pre>"},{"location":"API/util/base/","title":"Base","text":""},{"location":"API/util/base/#xlranker.util.safe_a_greater_or_equal_to_b","title":"<code>safe_a_greater_or_equal_to_b(a, b)</code>","text":"<p>returns True if a is greater or equal to b, with checks for None.</p> <p>None is treated as missing value. Any float is greater than None. If both are None, return True.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float | None</code> <p>a value</p> required <code>b</code> <code>float | None</code> <p>b value</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if a is greater or equal to b. If both are None, return True. Any float is greater than None.</p> Source code in <code>src/xlranker/util/__init__.py</code> <pre><code>def safe_a_greater_or_equal_to_b(a: float | None, b: float | None) -&gt; bool:\n    \"\"\"returns True if a is greater or equal to b, with checks for None.\n\n    None is treated as missing value. Any float is greater than None. If both are None, return True.\n\n    Args:\n        a (float | None): a value\n        b (float | None): b value\n\n    Returns:\n        bool: True if a is greater or equal to b. If both are None, return True. Any float is greater than None.\n    \"\"\"\n    if a is None:\n        return b is None  # if a is None, then if b is not None, b is greater\n    else:\n        if b is None:\n            return True  # Non-None is always greater than None\n        return a &gt;= b  # both are not None, so compare normally\n</code></pre>"},{"location":"API/util/base/#xlranker.util.set_seed","title":"<code>set_seed(seed)</code>","text":"<p>Set seed to provide consistent results between runs</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>number to initialize random number generators with</p> required Source code in <code>src/xlranker/util/__init__.py</code> <pre><code>def set_seed(seed: int) -&gt; None:\n    \"\"\"Set seed to provide consistent results between runs\n\n    Args:\n        seed (int): number to initialize random number generators with\n\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(int(random.random() * 1000000))\n</code></pre>"},{"location":"API/util/mappers/","title":"Mappers","text":"<p>Mapping related classes and functions.</p>"},{"location":"API/util/mappers/#xlranker.util.mapping.FastaType","title":"<code>FastaType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Types of Fasta files supported by XLRanker.</p> Source code in <code>src/xlranker/util/mapping.py</code> <pre><code>class FastaType(Enum):\n    \"\"\"Types of Fasta files supported by XLRanker.\"\"\"\n\n    UNIPROT = auto(), \"UNIPROT FASTA type\"\n    GENCODE = auto(), \"Gencode FASTA type\"\n</code></pre>"},{"location":"API/util/mappers/#xlranker.util.mapping.PeptideMapper","title":"<code>PeptideMapper</code>","text":"<p>Peptide mapper class.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Raises error if there is an issue with mapping tables</p> Source code in <code>src/xlranker/util/mapping.py</code> <pre><code>class PeptideMapper:\n    \"\"\"Peptide mapper class.\n\n    Raises:\n        ValueError: Raises error if there is an issue with mapping tables\n\n    \"\"\"\n\n    mapping_table_path: str\n    split_by: str\n    split_index: int\n    is_fasta: bool\n    fasta_type: FastaType\n\n    def __init__(\n        self,\n        mapping_table_path: str | None = None,\n        split_by: str = \"|\",\n        split_index: int = 3,\n        is_fasta: bool = True,\n        fasta_type: FastaType = FastaType.UNIPROT,\n    ) -&gt; None:\n        \"\"\"Initialize PeptideMapper.\n\n        Args:\n            mapping_table_path (str | None, optional): Path to mapping table.\n                                                       Can be in fasta or mapping table.\n                                                       If none, then uses the default uniprot version\n                                                       Defaults to None.\n            split_by (str, optional): character in fasta description to split into id components.\n                                      Defaults to \"|\".\n            split_index (int, optional): index of gene symbol in fasta file. Defaults to 3.\n            is_fasta (bool, optional): is input file fasta file. Defaults to True.\n            fasta_type (FastaType): Type of FASTA header. Can be UNIPROT or GENCODE\n\n        \"\"\"\n        if mapping_table_path is None:\n            logger.info(\"Using default gencode fasta file for peptide mapping\")\n            self.mapping_table_path = get_gencode_fasta()\n            # Make sure variables match defaults\n            split_by = \"|\"\n            split_index = 3\n            is_fasta = True\n        else:\n            logger.info(\"Using custom fasta file for peptide mapping\")\n            logging.debug(f\"FASTA File Path: {mapping_table_path}\")\n            self.mapping_table_path = mapping_table_path\n        self.split_by = split_by\n        self.split_index = split_index\n        self.is_fasta = is_fasta\n        self.fasta_type = fasta_type\n\n    def map_sequences(self, sequences: list[str]) -&gt; MappingResult:\n        \"\"\"Map a list of sequences to genes.\n\n        Args:\n            sequences (list[str]): list of sequences to map to genes\n\n        Returns:\n            dict[str, list[str]]: dictionary where keys are peptide sequences\n                                  values are list of genes that map to that sequence\n\n        \"\"\"\n        if self.is_fasta:  # determine which mapping function to use\n            map_res = self.map_fasta(sequences)\n        else:  # mapping table just needs to be read\n            map_res = MappingResult(\n                peptide_to_protein=read_mapping_table_file(self.mapping_table_path),\n                protein_sequences=None,\n            )\n        no_maps = 0\n        for seq in sequences:  # verify all sequences have mapping information\n            if seq not in map_res.peptide_to_protein:\n                logger.debug(f\"is_fasta: {self.is_fasta}\")\n                logger.warning(f\"{seq} not found in mapping table!\")\n            elif len(map_res.peptide_to_protein[seq]) == 0:\n                logger.debug(f\"is_fasta: {self.is_fasta}\")\n                logger.warning(f\"{seq} maps to no proteins!\")\n                no_maps += 1\n        if no_maps != 0:\n            logger.warning(f\"{no_maps} sequences do not have mapped proteins\")\n        return map_res\n\n    def map_fasta(self, sequences: list[str]) -&gt; MappingResult:\n        if config.reduce_fasta:\n            return self.map_fasta_with_reduction(sequences)\n        return self.map_fasta_no_reduction(sequences)\n\n    def map_fasta_no_reduction(self, sequences: list[str]) -&gt; MappingResult:\n        logger.debug(\"Mapping FASTA file without reduction\")\n        matches: dict[str, set[str]] = {}\n        for seq in sequences:\n            matches[seq] = set()\n        logger.info(f\"Mapping {len(sequences)} peptide sequences\")\n        for record in SeqIO.parse(self.mapping_table_path, \"fasta\"):\n            for sequence in sequences:\n                if sequence in record.seq:\n                    matches[sequence].add(\n                        extract_gene_symbol(\n                            record.description,\n                            self.fasta_type,\n                            split_by=self.split_by,\n                            split_index=self.split_index,\n                        )\n                    )\n\n        final_matches: dict[str, list[str]] = {}\n        for key in matches:\n            final_matches[key] = list(matches[key])\n        return MappingResult(peptide_to_protein=final_matches, protein_sequences=None)\n\n    def map_fasta_with_reduction(self, sequences: list[str]) -&gt; MappingResult:\n        logger.debug(\"Mapping FASTA file with reduction\")\n        matches: dict[str, set[str]] = {}\n        for seq in sequences:\n            matches[seq] = set()\n        logger.info(f\"Mapping {len(sequences)} peptide sequences\")\n        # First, build a mapping from gene symbol to its longest protein sequence\n        gene_to_longest_protein = {}\n        gene_to_longest_length: dict[str, int] = {}\n\n        for record in SeqIO.parse(self.mapping_table_path, \"fasta\"):\n            gene_symbol = extract_gene_symbol(\n                record.description,\n                self.fasta_type,\n                split_by=self.split_by,\n                split_index=self.split_index,\n            )\n            seq_str = str(record.seq)\n            seq_len = len(seq_str)\n            if (\n                gene_symbol not in gene_to_longest_length\n                or seq_len &gt; gene_to_longest_length[gene_symbol]\n            ):\n                gene_to_longest_length[gene_symbol] = seq_len\n                gene_to_longest_protein[gene_symbol] = seq_str\n\n        protein_sequences: dict[str, str] = {}\n        # Now, map sequences only if they are present in the longest protein sequence for that gene\n        for gene_symbol, protein_seq in gene_to_longest_protein.items():\n            mapped = False\n            for sequence in sequences:\n                if sequence in protein_seq:\n                    matches[sequence].add(gene_symbol)\n                    mapped = True\n            if mapped:\n                protein_sequences[gene_symbol] = protein_seq\n\n        final_matches: dict[str, list[str]] = {}\n        for key in matches:\n            final_matches[key] = list(matches[key])\n        return MappingResult(\n            peptide_to_protein=final_matches, protein_sequences=protein_sequences\n        )\n</code></pre>"},{"location":"API/util/mappers/#xlranker.util.mapping.PeptideMapper.__init__","title":"<code>__init__(mapping_table_path=None, split_by='|', split_index=3, is_fasta=True, fasta_type=FastaType.UNIPROT)</code>","text":"<p>Initialize PeptideMapper.</p> <p>Parameters:</p> Name Type Description Default <code>mapping_table_path</code> <code>str | None</code> <p>Path to mapping table.                                        Can be in fasta or mapping table.                                        If none, then uses the default uniprot version                                        Defaults to None.</p> <code>None</code> <code>split_by</code> <code>str</code> <p>character in fasta description to split into id components.                       Defaults to \"|\".</p> <code>'|'</code> <code>split_index</code> <code>int</code> <p>index of gene symbol in fasta file. Defaults to 3.</p> <code>3</code> <code>is_fasta</code> <code>bool</code> <p>is input file fasta file. Defaults to True.</p> <code>True</code> <code>fasta_type</code> <code>FastaType</code> <p>Type of FASTA header. Can be UNIPROT or GENCODE</p> <code>UNIPROT</code> Source code in <code>src/xlranker/util/mapping.py</code> <pre><code>def __init__(\n    self,\n    mapping_table_path: str | None = None,\n    split_by: str = \"|\",\n    split_index: int = 3,\n    is_fasta: bool = True,\n    fasta_type: FastaType = FastaType.UNIPROT,\n) -&gt; None:\n    \"\"\"Initialize PeptideMapper.\n\n    Args:\n        mapping_table_path (str | None, optional): Path to mapping table.\n                                                   Can be in fasta or mapping table.\n                                                   If none, then uses the default uniprot version\n                                                   Defaults to None.\n        split_by (str, optional): character in fasta description to split into id components.\n                                  Defaults to \"|\".\n        split_index (int, optional): index of gene symbol in fasta file. Defaults to 3.\n        is_fasta (bool, optional): is input file fasta file. Defaults to True.\n        fasta_type (FastaType): Type of FASTA header. Can be UNIPROT or GENCODE\n\n    \"\"\"\n    if mapping_table_path is None:\n        logger.info(\"Using default gencode fasta file for peptide mapping\")\n        self.mapping_table_path = get_gencode_fasta()\n        # Make sure variables match defaults\n        split_by = \"|\"\n        split_index = 3\n        is_fasta = True\n    else:\n        logger.info(\"Using custom fasta file for peptide mapping\")\n        logging.debug(f\"FASTA File Path: {mapping_table_path}\")\n        self.mapping_table_path = mapping_table_path\n    self.split_by = split_by\n    self.split_index = split_index\n    self.is_fasta = is_fasta\n    self.fasta_type = fasta_type\n</code></pre>"},{"location":"API/util/mappers/#xlranker.util.mapping.PeptideMapper.map_sequences","title":"<code>map_sequences(sequences)</code>","text":"<p>Map a list of sequences to genes.</p> <p>Parameters:</p> Name Type Description Default <code>sequences</code> <code>list[str]</code> <p>list of sequences to map to genes</p> required <p>Returns:</p> Type Description <code>MappingResult</code> <p>dict[str, list[str]]: dictionary where keys are peptide sequences                   values are list of genes that map to that sequence</p> Source code in <code>src/xlranker/util/mapping.py</code> <pre><code>def map_sequences(self, sequences: list[str]) -&gt; MappingResult:\n    \"\"\"Map a list of sequences to genes.\n\n    Args:\n        sequences (list[str]): list of sequences to map to genes\n\n    Returns:\n        dict[str, list[str]]: dictionary where keys are peptide sequences\n                              values are list of genes that map to that sequence\n\n    \"\"\"\n    if self.is_fasta:  # determine which mapping function to use\n        map_res = self.map_fasta(sequences)\n    else:  # mapping table just needs to be read\n        map_res = MappingResult(\n            peptide_to_protein=read_mapping_table_file(self.mapping_table_path),\n            protein_sequences=None,\n        )\n    no_maps = 0\n    for seq in sequences:  # verify all sequences have mapping information\n        if seq not in map_res.peptide_to_protein:\n            logger.debug(f\"is_fasta: {self.is_fasta}\")\n            logger.warning(f\"{seq} not found in mapping table!\")\n        elif len(map_res.peptide_to_protein[seq]) == 0:\n            logger.debug(f\"is_fasta: {self.is_fasta}\")\n            logger.warning(f\"{seq} maps to no proteins!\")\n            no_maps += 1\n    if no_maps != 0:\n        logger.warning(f\"{no_maps} sequences do not have mapped proteins\")\n    return map_res\n</code></pre>"},{"location":"API/util/mappers/#xlranker.util.mapping.extract_gene_symbol_gencode","title":"<code>extract_gene_symbol_gencode(fasta_description, **kwargs)</code>","text":"<p>Get the gene symbol from a UNIPROT style FASTA description.</p> <p>Method:</p> <ol> <li>Split the description by spaces</li> <li>Find split with GN= (Gene Name)</li> <li>Remove GN= from split and return</li> </ol> <p>If split with GN= not found, return the UNIPROT symbol.</p> <ol> <li>Using first split (when splitting by space), split again by |</li> <li>If there is at least 2 elements in split, return second element</li> </ol> <p>If can't get UNIPROT symbol, return original description.</p> <p>Parameters:</p> Name Type Description Default <code>fasta_description</code> <code>str</code> <p>FASTA description string</p> required <code>split_by</code> <code>str</code> <p>Character to split description string</p> required <code>split_index</code> <code>str</code> <p>Index (0-based) of gene symbol after splitting.                All characters after first space are removed.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Gene Symbol from description. If can't be extracted, return original description</p> Source code in <code>src/xlranker/util/mapping.py</code> <pre><code>def extract_gene_symbol_gencode(fasta_description: str, **kwargs) -&gt; str:\n    \"\"\"Get the gene symbol from a UNIPROT style FASTA description.\n\n    Method:\n\n    1. Split the description by spaces\n    2. Find split with GN= (Gene Name)\n    3. Remove GN= from split and return\n\n    If split with GN= not found, return the UNIPROT symbol.\n\n    1. Using first split (when splitting by space), split again by |\n    2. If there is at least 2 elements in split, return second element\n\n    If can't get UNIPROT symbol, return original description.\n\n    Args:\n        fasta_description (str): FASTA description string\n        split_by (str): Character to split description string\n        split_index (str): Index (0-based) of gene symbol after splitting.\n                           All characters after first space are removed.\n\n    Returns:\n        str: Gene Symbol from description. If can't be extracted, return original description\n\n    \"\"\"\n    split_by = kwargs[\"split_by\"]\n    split_index = kwargs[\"split_index\"]\n    split_res = fasta_description.split(split_by)\n    if split_index &gt;= len(split_res):\n        return split_res[0]  # keep first split if split_index is too large\n    if len(split_res) != 0:\n        return split_res[split_index].split(\" \")[0]  # remove elements after space\n    return fasta_description  # return if failed\n</code></pre>"},{"location":"API/util/mappers/#xlranker.util.mapping.extract_gene_symbol_uniprot","title":"<code>extract_gene_symbol_uniprot(fasta_description)</code>","text":"<p>Get the gene symbol from a UNIPROT style FASTA description.</p> <p>Method:</p> <ol> <li>Split the description by spaces</li> <li>Find split with GN= (Gene Name)</li> <li>Remove GN= from split and return</li> </ol> <p>If split with GN= not found, return the UNIPROT symbol.</p> <ol> <li>Using first split (when splitting by space), split again by |</li> <li>If there is at least 2 elements in split, return second element</li> </ol> <p>If can't get UNIPROT symbol, return original description.</p> <p>Parameters:</p> Name Type Description Default <code>fasta_description</code> <code>str</code> <p>FASTA description string</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Gene Symbol from description. If can't be extracted, try getting UNIPROT ID.  If all fails, return original description</p> Source code in <code>src/xlranker/util/mapping.py</code> <pre><code>def extract_gene_symbol_uniprot(fasta_description: str) -&gt; str:\n    \"\"\"Get the gene symbol from a UNIPROT style FASTA description.\n\n    Method:\n\n    1. Split the description by spaces\n    2. Find split with GN= (Gene Name)\n    3. Remove GN= from split and return\n\n    If split with GN= not found, return the UNIPROT symbol.\n\n    1. Using first split (when splitting by space), split again by |\n    2. If there is at least 2 elements in split, return second element\n\n    If can't get UNIPROT symbol, return original description.\n\n    Args:\n        fasta_description (str): FASTA description string\n\n    Returns:\n        str: Gene Symbol from description. If can't be extracted, try getting UNIPROT ID.\n             If all fails, return original description\n\n    \"\"\"\n    splits = fasta_description.split(\" \")\n    for split in splits:\n        if \"GN=\" in split:  # check if gene name split\n            return split[3:]  # Remove GN= from string\n    splits = splits[0].split(\"|\")\n    if len(splits) &gt;= 2:\n        return splits[1]\n    return fasta_description  # return if failed\n</code></pre>"},{"location":"API/util/readers/","title":"Readers","text":""},{"location":"API/util/readers/#xlranker.util.readers.read_data_folder","title":"<code>read_data_folder(folder_path, additional_null_values=[])</code>","text":"<p>Reads all TSV files in a folder</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str</code> <p>path of the folder that contains files ending in .tsv</p> required <code>additional_null_values</code> <code>list[str]</code> <p>list of str of additional values that should considered as null in the data files</p> <code>[]</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>raised if no TSV files are found</p> <p>Returns:</p> Type Description <code>dict[str, DataFrame]</code> <p>list[pl.DataFrame]: list of all of the data files in a Polars DataFrame, as read by the read_data_matrix function</p> Source code in <code>src/xlranker/util/readers.py</code> <pre><code>def read_data_folder(\n    folder_path: str, additional_null_values=[]\n) -&gt; dict[str, pl.DataFrame]:\n    \"\"\"Reads all TSV files in a folder\n\n    Args:\n        folder_path (str): path of the folder that contains files ending in .tsv\n        additional_null_values (list[str]): list of str of additional values that should considered as null in the data files\n\n    Raises:\n        FileNotFoundError: raised if no TSV files are found\n\n    Returns:\n        list[pl.DataFrame]: list of all of the data files in a Polars DataFrame, as read by the read_data_matrix function\n\n    \"\"\"\n    file_glob = Path(folder_path).glob(\"*.tsv\")\n    file_list: list[Path] = list(file_glob)\n    if len(file_list) == 0:\n        raise FileNotFoundError(f\"No TSV files were found in directory: {folder_path}\")\n    ret_dict = {}\n    for file in file_list:\n        ret_dict[base_name(file)] = read_data_matrix(\n            str(file), additional_null_values=config.additional_null_values\n        )\n    return ret_dict\n</code></pre>"},{"location":"API/util/readers/#xlranker.util.readers.read_data_matrix","title":"<code>read_data_matrix(data_path, additional_null_values=[])</code>","text":"<p>Reads data matrix into a Polars DataFrame with samples/measurements being columns.</p> Format <ul> <li>Has header (any names allowed).</li> <li>First column must be the protein/gene followed by measurements.</li> <li>Null/missing values: \"\", \"NA\". More can be added.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>str</code> <p>path to the data matrix</p> required <code>additional_null_values</code> <code>list[str]</code> <p>list of str of additional values that should considered as null</p> <code>[]</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pl.DataFrame: Polars DataFrame of the input data</p> Source code in <code>src/xlranker/util/readers.py</code> <pre><code>def read_data_matrix(\n    data_path: str, additional_null_values: list[str] = []\n) -&gt; pl.DataFrame:\n    \"\"\"Reads data matrix into a Polars DataFrame with samples/measurements being columns.\n\n    Format:\n     - Has header (any names allowed).\n     - First column must be the protein/gene followed by measurements.\n     - Null/missing values: \"\", \"NA\". More can be added.\n\n    Args:\n        data_path (str): path to the data matrix\n        additional_null_values (list[str]): list of str of additional values that should considered as null\n\n    Returns:\n        pl.DataFrame: Polars DataFrame of the input data\n\n    \"\"\"\n    null_values = [\"\", \"NA\"]\n    null_values.extend(additional_null_values)\n    return pl.read_csv(\n        data_path, has_header=True, separator=\"\\t\", null_values=null_values\n    )\n</code></pre>"},{"location":"API/util/readers/#xlranker.util.readers.read_mapping_table_file","title":"<code>read_mapping_table_file(file_path)</code>","text":"<p>Read mapping file where the first column is the peptide sequence and the following columns are proteins that map to that sequence.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>path to the tab-separated mapping table</p> required Source code in <code>src/xlranker/util/readers.py</code> <pre><code>def read_mapping_table_file(file_path: str) -&gt; dict[str, list[str]]:\n    \"\"\"Read mapping file where the first column is the peptide sequence and the following columns are proteins that map to that sequence.\n\n    Args:\n        file_path (str): path to the tab-separated mapping table\n\n    \"\"\"\n    try:\n        with open(file_path, mode=\"r\") as r:\n            raw_text = r.read().split(\"\\n\")\n        mapping_res: dict[str, list[str]] = dict()\n        uniq_sequences: set[str] = set()\n        for line in raw_text:\n            if \"\\t\" in line:\n                vals = line.split(\"\\t\")\n                seq = vals[0]\n                if seq in uniq_sequences:\n                    logging.warning(\n                        f\"Peptide sequence {seq} duplicated! Keeping first instance.\"\n                    )\n                else:\n                    uniq_sequences.add(seq)\n                    mapping_res[seq] = vals[1:]\n        if len(mapping_res) == 0:\n            logging.error(f\"No peptide sequences found in mapping file: {file_path}\")\n            raise ValueError(\"No peptide sequence identified\")\n        return mapping_res\n    except FileNotFoundError:\n        logging.error(f\"Could not find mapping table file at {file_path}!\")\n        raise ValueError(\"Could not read mapping table: File not found.\")\n</code></pre>"},{"location":"API/util/readers/#xlranker.util.readers.read_network_file","title":"<code>read_network_file(network_path)</code>","text":"<p>reads TSV network file to a list of PeptideGroup</p> <p>Parameters:</p> Name Type Description Default <code>network_path</code> <code>str</code> <p>path to the TSV file</p> required <p>Returns:</p> Type Description <code>dict[str, PeptidePair]</code> <p>list[PeptideGroup]: list of PeptideGroup representing the network</p> Source code in <code>src/xlranker/util/readers.py</code> <pre><code>def read_network_file(network_path: str) -&gt; dict[str, PeptidePair]:\n    \"\"\"reads TSV network file to a list of PeptideGroup\n\n    Args:\n        network_path (str): path to the TSV file\n\n    Returns:\n        list[PeptideGroup]: list of PeptideGroup representing the network\n\n    \"\"\"\n    try:\n        with open(network_path) as r:\n            text = r.read().split(\"\\n\")\n        new_rows = set()  # Track unique rows\n        valid_rows = 0  # Keeps track of number of edges in original file\n        for row in text:\n            if \"\\t\" in row:\n                valid_rows += 1\n                vals = row.split(\"\\t\")\n                val_a = vals[0]\n                val_b = vals[1]\n                if val_a &gt; val_b:  # Make sure edges are all sorted the same.\n                    temp = val_a\n                    val_a = val_b\n                    val_b = temp\n                new_rows.add(f\"{val_a}\\t{val_b}\")\n    except IndexError:\n        logger.error(\"Index out of bound. Make sure network is in the correct format.\")\n        raise IndexError()\n    except FileNotFoundError:\n        logger.error(f\"File not found: {network_path}\")\n        raise FileNotFoundError\n    duplicate_rows = valid_rows - len(new_rows)  # Count number of duplicated rows\n    if duplicate_rows &gt; 0:  # Send warning that duplicate edges were removed.\n        logger.warning(\n            f\"Found and removed {duplicate_rows} duplicated edge(s) in network.\"\n        )\n    network: dict[str, PeptidePair] = {}\n    for row in new_rows:\n        vals = row.split(\"\\t\")\n        a = Peptide(vals[0])\n        b = Peptide(vals[1])\n        group = PeptidePair(a, b)\n        network[get_pair_id(a, b)] = group\n    return network\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>Install <code>xlranker</code> using <code>pip</code> or other Python package managers.</p> <pre><code>pip install xlranker\n</code></pre> <p>This will install a <code>xlranker</code> command which can be used to run the pipeline. You can also use the library if you are using a Jupyter Notebook. For notebook users, please see the notebook example.</p>"},{"location":"usage/#input-data","title":"Input Data","text":"<p>The input data for <code>xlranker</code> are:</p> Peptide Pairs TSV file showing all of the identified Peptide Pairs in the dataset. Omic Data Omic data used by the machine learning model for prioritizing ambiguous pairs Custom Sequence Mapping (Strongly Recommended, Optional) By default, <code>xlranker</code> uses the human UNIPROT (accessed 5-30-2025) one sequence per gene to map peptide sequences to proteins. It is strongly recommended that you provide the same database used for mapping the proteomics data. You can provide either a FASTA file or a TSV table with mapping pre-computed Please read documentation for requirements. <p>The typical file structure for the input looks like</p> <pre><code>omic_data/\n\u251c\u2500\u2500 protein.tsv\n\u2514\u2500\u2500 rna.tsv\npeptide_network.tsv\n</code></pre>"},{"location":"usage/#running-the-pipeline","title":"Running the Pipeline","text":"Example Data <p>To test the pipeline or view the input data formatting, download the example data below</p> <p> Download example.tar.gz</p> <p>For most users, you would want to run the full pipeline. This can be achieved by running the following command:</p> <pre><code>xlranker start peptide_network.tsv omic_data/\n</code></pre> <p>This example assumes <code>peptide_pairs.tsv</code> is already prepared according to the instructions above and is in the current working directory.</p> <p>The CLI contains multiple feature flags, such as only using the parsimony selection, saving more data, and custom filtering options. To view all of the options, please see CLI option documentation</p>"},{"location":"usage/#output","title":"Output","text":"<p>The output of the pipeline contains two files and a folder</p> network.tsv TSV file of the final xl network, with all of the accepted pairs info.tsv TSV file showing all of the protein pairs with information about their prioritization status. plots/ Folder containing plots showing model performance and feature importance."},{"location":"usage/config/","title":"Config","text":"<p>Instead of setting multiple CLI options, you can create a config file.</p> <p>You can create a config using the <code>xlranker init</code> command. This will run an interactive prompt that will create a custom config. If you just want the default configs, run <code>xlranker init --default</code>.</p>"},{"location":"usage/config/#config-options","title":"Config Options","text":"network (Required) path to the network containing peptide sequences. Described in input_data/peptide_pairs. data_folder (Required) path to a directory containing multi-omic data used by the machine learning model. Described in input_data/omic_data. seed (Defaults to <code>None</code>) integer to seed random number generators. If not set, random seed selected. custom_mapping_table (Defaults to <code>None</code>, strongly recommended) path to a custom mapping table (recommended). Can either be a FASTA file or a TSV file. Described in input_data/fasta and input_data/custom_mapping_table. If not set, uses UNIPROT human one sequence per gene acquired on May 29, 2025. is_fasta (Defaults to <code>True</code>) <code>true</code> if the <code>custom_mapping_table</code> is a FASTA file. fasta_type Valid options <code>GENCODE</code> or <code>UNIPROT</code>. Type of FASTA file used. Must be set if custom_mapping_table is set. only_human (Defaults to <code>true</code>) <code>true</code> if the data in the pipeline only contains human data. If <code>true</code>, allows for better negative pair generation and PPI information. output (Defaults to <code>xlranker_output</code>) Output directory for the pipeline. Contains the final network, info file, and plots."},{"location":"usage/CLI_options/","title":"CLI Options","text":"<p>There are many customizable parameters for the <code>xlranker</code> CLI. To view all of the options, you can run</p> <pre><code>xlranker start --help\n</code></pre> <pre><code>Usage: xlranker start [ARGS] [OPTIONS]\n\nRun the full prioritization pipeline\n\nRequires input file to be in the format specified in the project documentation.\n\n\u256d\u2500 Parameters \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 NETWORK --network               -n  path to TSV file containing peptide         \u2502\n\u2502                                     network.                                    \u2502\n\u2502 DATA-FOLDER --data-folder       -d  folder containing the omics data for the    \u2502\n\u2502                                     model prediction.                           \u2502\n\u2502 CONFIG --config                 -c  if set, read and load options from config   \u2502\n\u2502                                     file. Can be in JSON or YAML format.        \u2502\n\u2502 SEED --seed                     -s  seed for machine learning pipeline. If not  \u2502\n\u2502                                     set, seed is randomly selected.             \u2502\n\u2502 VERBOSE --verbose --no-verbose  -v  enable verbose logging. [default: False]    \u2502\n\u2502 LOG-FILE --log-file             -l  if set, saves logging to path               \u2502\n\u2502 MAPPING-TABLE --mapping-table   -m  path to custom mapping table for peptide    \u2502\n\u2502                                     sequences                                   \u2502\n\u2502 SPLIT --split                       character used for splitting the FASTA file \u2502\n\u2502                                     header                                      \u2502\n\u2502 GS-INDEX --gs-index                 index in the FASTA file that contains the   \u2502\n\u2502                                     gene symbol. Index starts at 0.             \u2502\n\u2502 IS-FASTA --is-fasta                 Enable if mapping table is a FASTA file.    \u2502\n\u2502   --no-is-fasta                     [default: False]                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>Instead of setting these parameters each run, you can create a config file. To create the config file, run <code>xlranker init</code> or view the documentation.</p>"},{"location":"usage/input_data/custom_mapping_table/","title":"TSV Table Format","text":"<p>For Advanced Users</p> <p>xlranker provides peptide sequence mapping using FASTA files. This is typically good enough for most users, but for more complex use cases, you can perform the mapping yourself and follow the below instructions.</p> <p>The mapping table should be a tab-separated file where the first column in a line is the peptide sequence with the following columns being proteins (in Gene Symbol if possible) that map to that sequence. There are no restrictions on length, but the sequences in the mapping table must match the sequences given in the list of identified peptide pairs (see Peptide Pairs for more information).</p>"},{"location":"usage/input_data/custom_mapping_table/#example","title":"Example","text":"<pre><code>AVAWTLGVSHS     OR4F16  OR4F29\nPLLALPPQGPPG    SAMD11\n</code></pre> <p>In the above example, <code>AVAWTLGVSHS</code> maps to two proteins, while the second sequence is unambiguous.</p>"},{"location":"usage/input_data/fasta/","title":"FASTA File","text":"<p>By default, <code>xlranker</code> uses UNIPROT One Sequence Per Gene for mapping peptide sequences to gene symbols. However, it is strongly recommended to provide your own mapping file that matches what was used for generating the XL data. The FASTA file must provide a mechanism to getting the gene symbol. <code>xlranker</code> supports FASTA files in two formats: GENCODE and UNIPROT. If you provide your own FASTA file, provide the FASTA format with the <code>--fasta-type</code> flag in the CLI or in the config.</p> <p>FASTA files are not necessarily consistent and <code>xlranker</code> provides simple tools to try to allow for multiple formats. You can always perform the mapping yourself and use the TSV table format as input instead of the FASTA file.</p>"},{"location":"usage/input_data/fasta/#fasta-reduction","title":"FASTA Reduction","text":"<p>FASTA files may contain multiple sequences for the same gene symbol. <code>xlranker</code> will reduce the FASTA file to one sequence per gene symbol by default. This is done by accepting the largest sequence only. If you want to disable this behavior, you can use the <code>--no-reduce-fasta</code> flag in the CLI or set <code>reduce_fasta: false</code> in the config.</p>"},{"location":"usage/input_data/fasta/#example-uniprot-format","title":"Example - UNIPROT Format","text":"<pre><code>&gt;sp|P31946|1433B_HUMAN 14-3-3 protein beta/alpha OS=Homo sapiens OX=9606 GN=YWHAB PE=1 SV=3\nMTMDKSELVQKAKLAEQAERYDDMAAAMKAVTEQGHELSNEERNLLSVAYKNVVGARRSS\nWRVISSIEQKTERNEKKQQMGKEYREKIEAELQDICNDVLELLDKYLIPNATQPESKVFY\nLKMKGDYFRYLSEVASGDNKQTTVSNSQQAYQEAFEISKKEMQPTHPIRLGLALNFSVFY\nYEILNSPEKACSLAKTAFDEAIAELDTLNEESYKDSTLIMQLLRDNLTLWTSENQGDEGD\nAGEGEN\n</code></pre> <p>The UNIPROT FASTA format contains a <code>GN=</code> string in the description, which is set to the Gene Symbol representing a match that that FASTA entry.</p>"},{"location":"usage/input_data/fasta/#example-gencode-format","title":"Example - GENCODE Format","text":"<p>Below is an example FASTA entry from GENCODE v48</p> <pre><code>&gt;ENSP00000485175.1|ENST00000623578.3|ENSG00000169224.13|OTTHUMG00000040648.6|-|GCSAML-211|GCSAML|103\nMTTFERKLQDQDKKSQEVSSTSNQENENGSGSEEVCYTVINHIPHQRSSLSSNDDGYENI\nDSLTRKVRQFRERSETEYALLRTSVSRPCSCTHEHDYEVVFPH\n</code></pre> <p><code>xlranker</code> needs to know how to extract the gene symbol from the fasta description. You can provide the split character, and the index for the gene symbol. In the above example, the split character is <code>|</code> and the index of the gene symbol is 6 (0-based indexing).</p> <p>To test your custom mapping settings, you can use the <code>xlranker test-fasta --split \"|\" --gs-index 6 mapping.fa --fasta-type gencode</code> command. You should replace the arguments with your desired inputs. It will output the mapping for three peptide sequences using the provided parameters. Make sure the output is in gene symbol.</p>"},{"location":"usage/input_data/omic_data/","title":"Omic Data","text":"<p>The machine learning portion of the pipeline requires measurements that is used to prioritize ambiguous pairs. The input to the pipeline is a path to a folder containing data matrices. Traditionally, RNAseq and proteome data is provided.</p>"},{"location":"usage/input_data/omic_data/#data-format","title":"Data Format","text":"<p>The file should be a tab-separated file, with the first column being the protein/gene in Gene Symbol. The following columns are measurements in each sample. The value used for each gene is the mean measurement across all the included samples.</p> <p>Accepted values for missing values are: <code>NA</code> and blank.</p>"},{"location":"usage/input_data/omic_data/#example","title":"Example","text":"<pre><code>idx 11BR047 11BR043\nTSPAN6  23.5362298956281    21.6672110897463\nTNMD    NA  NA\nDPM1    26.0377091834862    25.6517806500539\nSCYL3   23.5747379833942    23.9216878914892\nFIRRM   18.22840670697  18.9470251111963\n</code></pre>"},{"location":"usage/input_data/peptide_pairs/","title":"Peptide Pairs","text":""},{"location":"usage/input_data/peptide_pairs/#format","title":"Format","text":"<p>The peptide pair table should be a two column tab-separated file with each column being a peptide sequence. Each row is a cross-linked peptide pair. The order of the sequences does not matter.</p>"},{"location":"usage/input_data/peptide_pairs/#example","title":"Example","text":"<pre><code>MPRIMIKGGVWR    LAADVGKAGAER\nELAKDTR GMKVIENR\nELAKDTR GMKVIENR\nELAKDTR GMKVIENR\nGMKVIENR    ALKDEEK\nALKDEEK GMKVIENR\n</code></pre>"},{"location":"usage/output/","title":"XLRanker Output","text":"<p>XLRanker generates multiple output files.</p> <ol> <li><code>model_output.tsv</code>: TSV file that contains the input features and prediction scores for pairs given to the ML model.</li> <li><code>Reports/</code>: Directory containing various reports. See Reports documentation for details.</li> </ol>"},{"location":"usage/output/reports/","title":"XLRanker Reports","text":"<p>XLRanker generates a variety of reports at different levels of confidence.</p>"}]}